"""
News Analyzer v1.0 - –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π, Twitter –∏ –º–∞–∫—Ä–æ-—Å–æ–±—ã—Ç–∏–π –¥–ª—è —Ç—Ä–µ–π–¥–∏–Ω–≥–∞
–û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç: Trump, –∫—Ä—É–ø–Ω—ã—Ö —Ç—Ä–µ–π–¥–µ—Ä–æ–≤, –≥–æ—Å. –æ—Ä–≥–∞–Ω—ã –°–®–ê, –∫—Ä–∏–ø—Ç–æ-–Ω–æ–≤–æ—Å—Ç–∏

–§—É–Ω–∫—Ü–∏–∏:
1. Twitter/X –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–ª—é—á–µ–≤—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤
2. RSS/API –Ω–æ–≤–æ—Å—Ç–∏ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç
3. Macro-—Å–æ–±—ã—Ç–∏—è (FOMC, CPI, NFP, —Ç–∞—Ä–∏—Ñ—ã)
4. Sentiment –∞–Ω–∞–ª–∏–∑
5. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤–æ—Å—Ç–µ–π
"""

import asyncio
import aiohttp
import logging
import re
import json
import hashlib
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from enum import Enum
from collections import deque

logger = logging.getLogger(__name__)

# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ====================

# –ö–ª—é—á–µ–≤—ã–µ Twitter –∞–∫–∫–∞—É–Ω—Ç—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
TWITTER_ACCOUNTS = {
    # === –ü–û–õ–ò–¢–ò–ö–ò ===
    'realDonaldTrump': {
        'name': 'Donald Trump',
        'type': 'politician',
        'impact': 'HIGH',
        'keywords': ['crypto', 'bitcoin', 'tariff', 'china', 'economy', 'fed', 'rate', 'dollar', 'trade']
    },
    'POTUS': {
        'name': 'President of the United States',
        'type': 'government',
        'impact': 'HIGH',
        'keywords': ['economy', 'trade', 'tariff', 'crypto', 'digital', 'regulation']
    },
    'WhiteHouse': {
        'name': 'White House',
        'type': 'government',
        'impact': 'HIGH',
        'keywords': ['economy', 'executive order', 'trade', 'china', 'policy']
    },
    'USTreasury': {
        'name': 'US Treasury',
        'type': 'government',
        'impact': 'HIGH',
        'keywords': ['sanctions', 'dollar', 'debt', 'crypto', 'stablecoin', 'regulation']
    },
    'SECGov': {
        'name': 'SEC',
        'type': 'regulator',
        'impact': 'CRITICAL',
        'keywords': ['crypto', 'bitcoin', 'ethereum', 'enforcement', 'etf', 'regulation', 'lawsuit']
    },
    'federalreserve': {
        'name': 'Federal Reserve',
        'type': 'central_bank',
        'impact': 'CRITICAL',
        'keywords': ['rate', 'inflation', 'fomc', 'powell', 'monetary', 'balance sheet']
    },
    
    # === –¢–û–ü –ö–†–ò–ü–¢–û-–¢–†–ï–ô–î–ï–†–´ ===
    'CryptoCred': {
        'name': 'Crypto Cred',
        'type': 'trader',
        'impact': 'MEDIUM',
        'keywords': ['long', 'short', 'btc', 'eth', 'entry', 'target', 'stop']
    },
    'HsakaTrades': {
        'name': 'Hsaka',
        'type': 'trader',
        'impact': 'MEDIUM',
        'keywords': ['long', 'short', 'btc', 'eth', 'sol', 'position', 'tp', 'sl']
    },
    'CryptoKaleo': {
        'name': 'Kaleo',
        'type': 'trader',
        'impact': 'MEDIUM',
        'keywords': ['btc', 'eth', 'alt', 'degen', 'pump', 'moon']
    },
    'ColdBloodShill': {
        'name': 'ColdBloodShill',
        'type': 'trader',
        'impact': 'MEDIUM',
        'keywords': ['btc', 'eth', 'alts', 'chart', 'setup']
    },
    'inversebrah': {
        'name': 'InverseBrah',
        'type': 'trader',
        'impact': 'MEDIUM',
        'keywords': ['perp', 'long', 'short', 'liquidation', 'funding']
    },
    'GCRClassic': {
        'name': 'GCR',
        'type': 'trader',
        'impact': 'HIGH',
        'keywords': ['btc', 'macro', 'cycle', 'bear', 'bull']
    },
    'loomdart': {
        'name': 'Loomdart',
        'type': 'trader',
        'impact': 'MEDIUM',
        'keywords': ['btc', 'eth', 'trade', 'analysis']
    },
    'PeterLBrandt': {
        'name': 'Peter Brandt',
        'type': 'trader',
        'impact': 'MEDIUM',
        'keywords': ['btc', 'pattern', 'chart', 'target']
    },
    
    # === –ö–†–ò–ü–¢–û –ò–ù–°–ê–ô–î–ï–†–´ ===
    'caborek': {
        'name': 'Caborek',
        'type': 'insider',
        'impact': 'HIGH',
        'keywords': ['blackrock', 'etf', 'flow', 'institutional']
    },
    'WuBlockchain': {
        'name': 'Wu Blockchain',
        'type': 'news',
        'impact': 'HIGH',
        'keywords': ['china', 'mining', 'regulation', 'exchange', 'binance']
    },
    'FatManTerra': {
        'name': 'FatMan',
        'type': 'investigator',
        'impact': 'HIGH',
        'keywords': ['scam', 'fraud', 'warning', 'insolvency', 'hack']
    },
    'zachxbt': {
        'name': 'ZachXBT',
        'type': 'investigator',
        'impact': 'HIGH',
        'keywords': ['scam', 'hack', 'exploit', 'stolen', 'investigation']
    },
    
    # === –ë–ò–†–ñ–ò –ò –ü–†–û–ï–ö–¢–´ ===
    'binance': {
        'name': 'Binance',
        'type': 'exchange',
        'impact': 'HIGH',
        'keywords': ['listing', 'delist', 'maintenance', 'withdrawal', 'announcement']
    },
    'coinaborek': {
        'name': 'Coinbase',
        'type': 'exchange',
        'impact': 'HIGH',
        'keywords': ['listing', 'sec', 'legal', 'announcement']
    },
    'caborek': {
        'name': 'Grayscale',
        'type': 'fund',
        'impact': 'HIGH',
        'keywords': ['btc', 'eth', 'outflow', 'inflow', 'etf']
    },
    
    # === –≠–ö–û–ù–û–ú–ò–ö–ê ===
    'elaborianmusk': {
        'name': 'Elon Musk',
        'type': 'influencer',
        'impact': 'HIGH',
        'keywords': ['doge', 'bitcoin', 'crypto', 'tesla']
    },
    'michaeljsaylor': {
        'name': 'Michael Saylor',
        'type': 'bitcoin_bull',
        'impact': 'MEDIUM',
        'keywords': ['bitcoin', 'btc', 'microstrategy', 'buy', 'acquisition']
    }
}

# –ö—Ä–∏–ø—Ç–æ-—Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
BULLISH_KEYWORDS = [
    'bullish', 'moon', 'pump', 'breakout', 'ath', 'new high', 'adoption',
    'institutional', 'etf approved', 'blackrock', 'buy', 'long', 'accumulate',
    'bottom', 'reversal', 'support holding', 'green', 'rally', 'surge',
    'approval', 'partnership', 'integration', 'listing', 'mainnet', 'upgrade'
]

BEARISH_KEYWORDS = [
    'bearish', 'dump', 'crash', 'breakdown', 'new low', 'ban', 'regulation',
    'lawsuit', 'sec', 'enforcement', 'sell', 'short', 'distribute',
    'top', 'resistance', 'rejection', 'red', 'plunge', 'collapse',
    'hack', 'exploit', 'scam', 'insolvency', 'bankruptcy', 'delisting',
    'tariff', 'sanctions', 'war', 'recession'
]

NEUTRAL_HIGH_IMPACT = [
    'fomc', 'fed', 'cpi', 'nfp', 'gdp', 'inflation', 'rate decision',
    'powell', 'yellen', 'trump', 'executive order', 'announcement'
]

# –ú–∞–∫—Ä–æ-—Å–æ–±—ã—Ç–∏—è –∫–∞–ª–µ–Ω–¥–∞—Ä—å (UTC)
MACRO_EVENTS = {
    'FOMC': {
        'impact': 'CRITICAL',
        'typical_days': [2, 3],  # Wed-Thu
        'typical_hours': [18, 19],  # 6-7 PM UTC
        'description': 'Federal Reserve Rate Decision'
    },
    'CPI': {
        'impact': 'CRITICAL',
        'typical_days': list(range(7)),  # Any day
        'typical_hours': [12, 13],  # 12-1 PM UTC
        'description': 'Consumer Price Index'
    },
    'NFP': {
        'impact': 'HIGH',
        'typical_days': [4],  # Friday
        'typical_hours': [12, 13],
        'description': 'Non-Farm Payrolls'
    },
    'GDP': {
        'impact': 'HIGH',
        'typical_days': list(range(7)),
        'typical_hours': [12, 13],
        'description': 'Gross Domestic Product'
    },
    'PCE': {
        'impact': 'HIGH',
        'typical_days': list(range(7)),
        'typical_hours': [12, 13],
        'description': 'Personal Consumption Expenditures'
    }
}

# News APIs
NEWS_SOURCES = {
    'cryptopanic': 'https://cryptopanic.com/api/v1/posts/?auth_token={api_key}&currencies=BTC,ETH,SOL&filter=hot',
    'coingecko_news': 'https://api.coingecko.com/api/v3/status_updates',
    'fear_greed': 'https://api.alternative.me/fng/?limit=1'
}


# ==================== –¢–ò–ü–´ –î–ê–ù–ù–´–• ====================

class NewsImpact(Enum):
    """–í–ª–∏—è–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –Ω–∞ —Ä—ã–Ω–æ–∫"""
    CRITICAL = 5  # –ú–æ–∂–µ—Ç –¥–≤–∏–Ω—É—Ç—å —Ä—ã–Ω–æ–∫ –Ω–∞ 5-10%+
    HIGH = 4      # 2-5% –¥–≤–∏–∂–µ–Ω–∏–µ
    MEDIUM = 3    # 1-2% –¥–≤–∏–∂–µ–Ω–∏–µ
    LOW = 2       # <1% –¥–≤–∏–∂–µ–Ω–∏–µ
    NOISE = 1     # –®—É–º, –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å


class NewsSentiment(Enum):
    """–°–µ–Ω—Ç–∏–º–µ–Ω—Ç –Ω–æ–≤–æ—Å—Ç–∏"""
    VERY_BULLISH = 2
    BULLISH = 1
    NEUTRAL = 0
    BEARISH = -1
    VERY_BEARISH = -2


class NewsCategory(Enum):
    """–ö–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–æ–≤–æ—Å—Ç–∏"""
    REGULATION = 'regulation'
    MACRO = 'macro'
    TARIFFS = 'tariffs'
    HACK_EXPLOIT = 'hack'
    LISTING = 'listing'
    PARTNERSHIP = 'partnership'
    WHALE_MOVE = 'whale'
    TRADER_CALL = 'trader_call'
    POLITICAL = 'political'
    TECHNICAL = 'technical'
    OTHER = 'other'


@dataclass
class NewsEvent:
    """–ù–æ–≤–æ—Å—Ç–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ"""
    id: str
    source: str
    author: str
    title: str
    content: str
    url: str
    timestamp: datetime
    sentiment: NewsSentiment
    impact: NewsImpact
    category: NewsCategory
    affected_coins: List[str]
    keywords_found: List[str]
    confidence: float  # 0-1
    trading_signal: Optional[str] = None  # 'LONG', 'SHORT', None
    reasoning: List[str] = field(default_factory=list)


@dataclass
class MacroEvent:
    """–ú–∞–∫—Ä–æ-—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–æ–µ —Å–æ–±—ã—Ç–∏–µ"""
    name: str
    description: str
    scheduled_time: datetime
    impact: NewsImpact
    actual_value: Optional[float] = None
    forecast_value: Optional[float] = None
    previous_value: Optional[float] = None
    surprise: Optional[float] = None  # actual - forecast


@dataclass
class TradingSignal:
    """–¢–æ—Ä–≥–æ–≤—ã–π —Å–∏–≥–Ω–∞–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤–æ—Å—Ç–µ–π"""
    direction: str  # 'LONG' –∏–ª–∏ 'SHORT'
    confidence: float  # 0-1
    source: str  # –ò—Å—Ç–æ—á–Ω–∏–∫ —Å–∏–≥–Ω–∞–ª–∞
    reasoning: List[str]
    affected_coins: List[str]
    time_sensitive: bool  # –ù—É–∂–Ω–æ –ª–∏ –¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ
    expires_at: datetime  # –ö–æ–≥–¥–∞ —Å–∏–≥–Ω–∞–ª –∏—Å—Ç–µ–∫–∞–µ—Ç
    impact: NewsImpact


# ==================== NEWS ANALYZER ====================

class NewsAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π –∏ Twitter –¥–ª—è —Ç—Ä–µ–π–¥–∏–Ω–≥–∞"""
    
    def __init__(self, cryptopanic_api_key: str = None):
        self.cryptopanic_key = cryptopanic_api_key
        
        # –ö—ç—à –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –¥—É–±–ª–µ–π
        self.seen_news: deque = deque(maxlen=1000)
        self.recent_events: deque = deque(maxlen=100)
        
        # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç
        self.market_sentiment = {
            'score': 0,  # -100 to +100
            'trend': 'NEUTRAL',  # BULLISH, BEARISH, NEUTRAL
            'last_update': None
        }
        
        # –ö—ç—à –¥–ª—è API
        self._cache: Dict[str, Tuple[Any, datetime]] = {}
        self._cache_ttl = 60  # —Å–µ–∫—É–Ω–¥
        
        logger.info("[NEWS] Analyzer initialized")
    
    def _get_news_hash(self, title: str, source: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ —Ö—ç—à–∞ –Ω–æ–≤–æ—Å—Ç–∏"""
        content = f"{title}:{source}".lower()
        return hashlib.md5(content.encode()).hexdigest()[:16]
    
    def _is_cached(self, key: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞"""
        if key in self._cache:
            data, timestamp = self._cache[key]
            if datetime.now() - timestamp < timedelta(seconds=self._cache_ttl):
                return True
        return False
    
    def _get_cached(self, key: str) -> Any:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–∑ –∫—ç—à–∞"""
        if key in self._cache:
            return self._cache[key][0]
        return None
    
    def _set_cache(self, key: str, value: Any):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –∫—ç—à"""
        self._cache[key] = (value, datetime.now())
    
    # ==================== SENTIMENT ANALYSIS ====================
    
    def analyze_sentiment(self, text: str) -> Tuple[NewsSentiment, float, List[str]]:
        """
        –ê–Ω–∞–ª–∏–∑ —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞ —Ç–µ–∫—Å—Ç–∞
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (sentiment, confidence, found_keywords)
        """
        text_lower = text.lower()
        found_keywords = []
        
        bullish_score = 0
        bearish_score = 0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±—ã—á—å–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        for keyword in BULLISH_KEYWORDS:
            if keyword in text_lower:
                bullish_score += 1
                found_keywords.append(f"‚úÖ {keyword}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ–¥–≤–µ–∂—å–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        for keyword in BEARISH_KEYWORDS:
            if keyword in text_lower:
                bearish_score += 1
                found_keywords.append(f"‚ùå {keyword}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –≤—ã—Å–æ–∫–æ-–∏–º–ø–∞–∫—Ç–Ω—ã–µ
        for keyword in NEUTRAL_HIGH_IMPACT:
            if keyword in text_lower:
                found_keywords.append(f"‚ö° {keyword}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç
        total_score = bullish_score - bearish_score
        total_keywords = bullish_score + bearish_score
        
        if total_keywords == 0:
            return NewsSentiment.NEUTRAL, 0.3, found_keywords
        
        confidence = min(0.9, 0.4 + (total_keywords * 0.1))
        
        if total_score >= 3:
            return NewsSentiment.VERY_BULLISH, confidence, found_keywords
        elif total_score >= 1:
            return NewsSentiment.BULLISH, confidence, found_keywords
        elif total_score <= -3:
            return NewsSentiment.VERY_BEARISH, confidence, found_keywords
        elif total_score <= -1:
            return NewsSentiment.BEARISH, confidence, found_keywords
        else:
            return NewsSentiment.NEUTRAL, confidence, found_keywords
    
    def detect_category(self, text: str, source: str) -> NewsCategory:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é –Ω–æ–≤–æ—Å—Ç–∏"""
        text_lower = text.lower()
        
        if any(w in text_lower for w in ['sec', 'regulation', 'lawsuit', 'enforcement', 'ban', 'legal']):
            return NewsCategory.REGULATION
        elif any(w in text_lower for w in ['fomc', 'fed', 'cpi', 'nfp', 'inflation', 'rate', 'powell']):
            return NewsCategory.MACRO
        elif any(w in text_lower for w in ['tariff', 'trade war', 'china', 'sanctions']):
            return NewsCategory.TARIFFS
        elif any(w in text_lower for w in ['hack', 'exploit', 'stolen', 'breach', 'vulnerability']):
            return NewsCategory.HACK_EXPLOIT
        elif any(w in text_lower for w in ['listing', 'delist', 'launch', 'mainnet']):
            return NewsCategory.LISTING
        elif any(w in text_lower for w in ['partnership', 'integration', 'collaboration']):
            return NewsCategory.PARTNERSHIP
        elif any(w in text_lower for w in ['whale', 'large transfer', 'moved', 'billion']):
            return NewsCategory.WHALE_MOVE
        elif source in ['trader'] or any(w in text_lower for w in ['long', 'short', 'entry', 'target']):
            return NewsCategory.TRADER_CALL
        elif any(w in text_lower for w in ['trump', 'biden', 'congress', 'senate', 'executive order']):
            return NewsCategory.POLITICAL
        else:
            return NewsCategory.OTHER
    
    def extract_coins(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á—å —É–ø–æ–º—è–Ω—É—Ç—ã–µ –º–æ–Ω–µ—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        coins = []
        text_upper = text.upper()
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–æ–Ω–µ—Ç—ã
        coin_patterns = [
            'BTC', 'BITCOIN', 'ETH', 'ETHEREUM', 'SOL', 'SOLANA',
            'XRP', 'RIPPLE', 'BNB', 'DOGE', 'DOGECOIN', 'ADA', 'CARDANO',
            'AVAX', 'DOT', 'MATIC', 'LINK', 'UNI', 'ATOM', 'LTC',
            'NEAR', 'APT', 'ARB', 'OP', 'SUI', 'SEI', 'INJ', 'TIA',
            'PEPE', 'SHIB', 'FLOKI', 'BONK', 'WIF', 'MEME',
            'FET', 'RNDR', 'TAO', 'WLD', 'ARKM'
        ]
        
        for pattern in coin_patterns:
            if pattern in text_upper:
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
                normalized = pattern.replace('BITCOIN', 'BTC').replace('ETHEREUM', 'ETH')
                normalized = normalized.replace('SOLANA', 'SOL').replace('RIPPLE', 'XRP')
                normalized = normalized.replace('DOGECOIN', 'DOGE').replace('CARDANO', 'ADA')
                if normalized not in coins:
                    coins.append(normalized)
        
        return coins if coins else ['BTC']  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é BTC
    
    def calculate_impact(self, source_type: str, category: NewsCategory, 
                         sentiment_strength: int) -> NewsImpact:
        """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å –≤–ª–∏—è–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏"""
        base_impact = 2  # LOW
        
        # –ü–æ –∏—Å—Ç–æ—á–Ω–∏–∫—É
        if source_type in ['regulator', 'central_bank']:
            base_impact = 5  # CRITICAL
        elif source_type in ['government', 'politician']:
            base_impact = 4  # HIGH
        elif source_type in ['exchange', 'investigator']:
            base_impact = 4  # HIGH
        elif source_type in ['trader', 'insider']:
            base_impact = 3  # MEDIUM
        
        # –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        if category in [NewsCategory.REGULATION, NewsCategory.MACRO]:
            base_impact = max(base_impact, 4)
        elif category in [NewsCategory.HACK_EXPLOIT, NewsCategory.TARIFFS]:
            base_impact = max(base_impact, 4)
        
        # –ü–æ —Å–∏–ª–µ —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞
        if abs(sentiment_strength) >= 2:
            base_impact = min(5, base_impact + 1)
        
        return NewsImpact(min(5, max(1, base_impact)))
    
    # ==================== NEWS FETCHING ====================
    
    async def fetch_cryptopanic_news(self) -> List[NewsEvent]:
        """–ü–æ–ª—É—á–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ —Å CryptoPanic"""
        if not self.cryptopanic_key:
            return []
        
        cache_key = 'cryptopanic'
        if self._is_cached(cache_key):
            return self._get_cached(cache_key)
        
        events = []
        
        try:
            url = f"https://cryptopanic.com/api/v1/posts/?auth_token={self.cryptopanic_key}&filter=hot&public=true"
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=aiohttp.ClientTimeout(total=10)) as resp:
                    if resp.status != 200:
                        return events
                    
                    data = await resp.json()
            
            for post in data.get('results', [])[:20]:
                title = post.get('title', '')
                news_hash = self._get_news_hash(title, 'cryptopanic')
                
                if news_hash in self.seen_news:
                    continue
                
                self.seen_news.append(news_hash)
                
                sentiment, confidence, keywords = self.analyze_sentiment(title)
                category = self.detect_category(title, 'news')
                coins = self.extract_coins(title)
                impact = self.calculate_impact('news', category, sentiment.value)
                
                event = NewsEvent(
                    id=news_hash,
                    source='CryptoPanic',
                    author=post.get('source', {}).get('title', 'Unknown'),
                    title=title,
                    content=title,
                    url=post.get('url', ''),
                    timestamp=datetime.fromisoformat(post.get('created_at', '').replace('Z', '+00:00')),
                    sentiment=sentiment,
                    impact=impact,
                    category=category,
                    affected_coins=coins,
                    keywords_found=keywords,
                    confidence=confidence
                )
                
                events.append(event)
            
            self._set_cache(cache_key, events)
            logger.info(f"[NEWS] Fetched {len(events)} news from CryptoPanic")
            
        except Exception as e:
            logger.warning(f"[NEWS] CryptoPanic error: {e}")
        
        return events
    
    async def fetch_fear_greed_index(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω–¥–µ–∫—Å —Å—Ç—Ä–∞—Ö–∞ –∏ –∂–∞–¥–Ω–æ—Å—Ç–∏"""
        cache_key = 'fear_greed'
        if self._is_cached(cache_key):
            return self._get_cached(cache_key)
        
        result = {
            'value': 50,
            'classification': 'Neutral',
            'timestamp': datetime.now(timezone.utc)
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    'https://api.alternative.me/fng/?limit=1',
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        if data.get('data'):
                            fg = data['data'][0]
                            result['value'] = int(fg.get('value', 50))
                            result['classification'] = fg.get('value_classification', 'Neutral')
            
            self._set_cache(cache_key, result)
            logger.info(f"[NEWS] Fear & Greed: {result['value']} ({result['classification']})")
            
        except Exception as e:
            logger.warning(f"[NEWS] Fear & Greed error: {e}")
        
        return result
    
    async def fetch_twitter_sentiment(self, accounts: List[str] = None) -> List[NewsEvent]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∫—Ä–∏–ø—Ç–æ-–Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –†–ê–ë–û–¢–ê–Æ–©–ò–• –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:
        1. CoinTelegraph RSS
        2. Decrypt RSS
        3. TheBlock RSS
        4. Bitcoin Magazine RSS
        5. CryptoSlate RSS
        """
        events = []
        
        # –†–∞–±–æ—Ç–∞—é—â–∏–µ RSS –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∫—Ä–∏–ø—Ç–æ-–Ω–æ–≤–æ—Å—Ç–µ–π
        rss_sources = [
            {
                'url': 'https://cointelegraph.com/rss',
                'name': 'CoinTelegraph',
                'type': 'news',
                'impact': 'HIGH'
            },
            {
                'url': 'https://decrypt.co/feed',
                'name': 'Decrypt',
                'type': 'news',
                'impact': 'HIGH'
            },
            {
                'url': 'https://www.theblock.co/rss.xml',
                'name': 'TheBlock',
                'type': 'news',
                'impact': 'HIGH'
            },
            {
                'url': 'https://bitcoinmagazine.com/.rss/full/',
                'name': 'Bitcoin Magazine',
                'type': 'news',
                'impact': 'MEDIUM'
            },
            {
                'url': 'https://cryptoslate.com/feed/',
                'name': 'CryptoSlate',
                'type': 'news',
                'impact': 'MEDIUM'
            },
            {
                'url': 'https://www.coindesk.com/arc/outboundfeeds/rss/',
                'name': 'CoinDesk',
                'type': 'news',
                'impact': 'HIGH'
            }
        ]
        
        for source in rss_sources:
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(
                        source['url'],
                        timeout=aiohttp.ClientTimeout(total=10),
                        headers={
                            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                            'Accept': 'application/rss+xml, application/xml, text/xml'
                        }
                    ) as resp:
                        if resp.status != 200:
                            logger.debug(f"[NEWS] {source['name']} returned {resp.status}")
                            continue
                        
                        content = await resp.text()
                
                # –ü–∞—Ä—Å–∏–º RSS
                items = re.findall(r'<item>(.*?)</item>', content, re.DOTALL | re.IGNORECASE)
                
                if not items:
                    # –ü–æ–ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (Atom)
                    items = re.findall(r'<entry>(.*?)</entry>', content, re.DOTALL | re.IGNORECASE)
                
                for item in items[:10]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –Ω–æ–≤–æ—Å—Ç–µ–π
                    # –ü–∞—Ä—Å–∏–º title
                    title_match = re.search(r'<title[^>]*>(.*?)</title>', item, re.DOTALL)
                    if not title_match:
                        continue
                    
                    title = title_match.group(1)
                    title = re.sub(r'<!\[CDATA\[(.*?)\]\]>', r'\1', title)  # –£–±–∏—Ä–∞–µ–º CDATA
                    title = re.sub(r'<[^>]+>', '', title)  # –£–±–∏—Ä–∞–µ–º HTML —Ç–µ–≥–∏
                    title = title.strip()
                    
                    if not title or len(title) < 10:
                        continue
                    
                    news_hash = self._get_news_hash(title, source['name'])
                    if news_hash in self.seen_news:
                        continue
                    
                    self.seen_news.append(news_hash)
                    
                    # –ü–∞—Ä—Å–∏–º —Å—Å—ã–ª–∫—É
                    link_match = re.search(r'<link[^>]*>([^<]+)</link>', item)
                    if not link_match:
                        link_match = re.search(r'<link[^>]*href=["\']([^"\']+)["\']', item)
                    url = link_match.group(1) if link_match else ''
                    
                    # –ü–∞—Ä—Å–∏–º –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                    desc_match = re.search(r'<description[^>]*>(.*?)</description>', item, re.DOTALL)
                    description = ''
                    if desc_match:
                        description = re.sub(r'<!\[CDATA\[(.*?)\]\]>', r'\1', desc_match.group(1))
                        description = re.sub(r'<[^>]+>', '', description)[:200]
                    
                    # –ê–Ω–∞–ª–∏–∑
                    full_text = f"{title} {description}"
                    sentiment, confidence, keywords = self.analyze_sentiment(full_text)
                    category = self.detect_category(full_text, source['type'])
                    coins = self.extract_coins(full_text)
                    impact = self.calculate_impact(source['type'], category, sentiment.value)
                    
                    # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É
                    timestamp = datetime.now(timezone.utc)
                    date_match = re.search(r'<pubDate>(.*?)</pubDate>', item)
                    if not date_match:
                        date_match = re.search(r'<published>(.*?)</published>', item)
                    if date_match:
                        try:
                            from email.utils import parsedate_to_datetime
                            timestamp = parsedate_to_datetime(date_match.group(1))
                        except:
                            try:
                                # ISO format fallback
                                timestamp = datetime.fromisoformat(date_match.group(1).replace('Z', '+00:00'))
                            except:
                                pass
                    
                    event = NewsEvent(
                        id=news_hash,
                        source=source['name'],
                        author=source['name'],
                        title=title[:200],
                        content=description or title,
                        url=url,
                        timestamp=timestamp,
                        sentiment=sentiment,
                        impact=impact,
                        category=category,
                        affected_coins=coins,
                        keywords_found=keywords,
                        confidence=confidence
                    )
                    
                    events.append(event)
                
                logger.debug(f"[NEWS] {source['name']}: parsed {len(items)} items")
                
            except Exception as e:
                logger.debug(f"[NEWS] {source['name']} error: {e}")
                continue
            
            await asyncio.sleep(0.3)  # Rate limiting
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        events.sort(key=lambda x: x.timestamp, reverse=True)
        
        logger.info(f"[NEWS] Fetched {len(events)} news from RSS sources")
        return events
    
    async def fetch_coingecko_trending(self) -> List[NewsEvent]:
        """
        –ü–æ–ª—É—á–∏—Ç—å trending –º–æ–Ω–µ—Ç—ã —Å CoinGecko - —Ö–æ—Ä–æ—à–∏–π –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä —Ö–∞–π–ø–∞
        """
        events = []
        
        try:
            async with aiohttp.ClientSession() as session:
                # Trending coins
                async with session.get(
                    'https://api.coingecko.com/api/v3/search/trending',
                    timeout=aiohttp.ClientTimeout(total=10),
                    headers={'Accept': 'application/json'}
                ) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        
                        for idx, coin_data in enumerate(data.get('coins', [])[:7]):
                            coin = coin_data.get('item', {})
                            name = coin.get('name', '')
                            symbol = coin.get('symbol', '').upper()
                            
                            if not symbol:
                                continue
                            
                            # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤–æ—Å—Ç—å –æ trending –º–æ–Ω–µ—Ç–µ
                            title = f"üî• {symbol} trending #{idx+1} on CoinGecko"
                            
                            news_hash = self._get_news_hash(f"trending_{symbol}", "coingecko")
                            if news_hash in self.seen_news:
                                continue
                            self.seen_news.append(news_hash)
                            
                            # Trending = –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ bullish (—Ö–∞–π–ø)
                            event = NewsEvent(
                                id=news_hash,
                                source='CoinGecko Trending',
                                author='CoinGecko',
                                title=title,
                                content=f"{name} ({symbol}) is trending",
                                url=f"https://www.coingecko.com/en/coins/{coin.get('id', '')}",
                                timestamp=datetime.now(timezone.utc),
                                sentiment=NewsSentiment.BULLISH,
                                impact=NewsImpact.MEDIUM,
                                category=NewsCategory.OTHER,
                                affected_coins=[symbol],
                                keywords_found=['trending', 'hype'],
                                confidence=0.5 + (0.05 * (7 - idx))  # Higher rank = higher confidence
                            )
                            events.append(event)
                
                logger.info(f"[NEWS] CoinGecko trending: {len(events)} coins")
                
        except Exception as e:
            logger.debug(f"[NEWS] CoinGecko error: {e}")
        
        return events
    
    async def fetch_binance_announcements(self) -> List[NewsEvent]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤–∞–∂–Ω—ã–µ –∞–Ω–æ–Ω—Å—ã —Å Binance (–ª–∏—Å—Ç–∏–Ω–≥–∏, –¥–µ–ª–∏—Å—Ç–∏–Ω–≥–∏)
        """
        events = []
        
        try:
            async with aiohttp.ClientSession() as session:
                # Binance announcements API
                async with session.get(
                    'https://www.binance.com/bapi/composite/v1/public/cms/article/list/query',
                    params={
                        'type': 1,
                        'pageNo': 1,
                        'pageSize': 20
                    },
                    timeout=aiohttp.ClientTimeout(total=10),
                    headers={
                        'User-Agent': 'Mozilla/5.0',
                        'Accept': 'application/json'
                    }
                ) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        
                        articles = data.get('data', {}).get('catalogs', [])
                        
                        for catalog in articles:
                            for article in catalog.get('articles', [])[:10]:
                                title = article.get('title', '')
                                
                                if not title:
                                    continue
                                
                                news_hash = self._get_news_hash(title, "binance")
                                if news_hash in self.seen_news:
                                    continue
                                self.seen_news.append(news_hash)
                                
                                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∞–Ω–æ–Ω—Å–∞
                                title_lower = title.lower()
                                
                                if 'list' in title_lower and 'delist' not in title_lower:
                                    sentiment = NewsSentiment.VERY_BULLISH
                                    impact = NewsImpact.HIGH
                                    category = NewsCategory.LISTING
                                elif 'delist' in title_lower or 'remove' in title_lower:
                                    sentiment = NewsSentiment.VERY_BEARISH
                                    impact = NewsImpact.HIGH
                                    category = NewsCategory.LISTING
                                elif 'maintenance' in title_lower or 'suspend' in title_lower:
                                    sentiment = NewsSentiment.BEARISH
                                    impact = NewsImpact.MEDIUM
                                    category = NewsCategory.OTHER
                                else:
                                    sentiment = NewsSentiment.NEUTRAL
                                    impact = NewsImpact.LOW
                                    category = NewsCategory.OTHER
                                
                                coins = self.extract_coins(title)
                                
                                event = NewsEvent(
                                    id=news_hash,
                                    source='Binance',
                                    author='Binance',
                                    title=title[:200],
                                    content=title,
                                    url=f"https://www.binance.com/en/support/announcement",
                                    timestamp=datetime.now(timezone.utc),
                                    sentiment=sentiment,
                                    impact=impact,
                                    category=category,
                                    affected_coins=coins,
                                    keywords_found=[],
                                    confidence=0.7 if impact.value >= NewsImpact.HIGH.value else 0.5
                                )
                                events.append(event)
                
                logger.info(f"[NEWS] Binance announcements: {len(events)}")
                
        except Exception as e:
            logger.debug(f"[NEWS] Binance announcements error: {e}")
        
        return events
    
    # ==================== MACRO EVENTS ====================
    
    def get_upcoming_macro_events(self, hours_ahead: int = 24) -> List[MacroEvent]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å—Ç–æ—è—â–∏–µ –º–∞–∫—Ä–æ-—Å–æ–±—ã—Ç–∏—è"""
        events = []
        now = datetime.now(timezone.utc)
        
        # –£–ø—Ä–æ—â—ë–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞: –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—É—â–∏–π –¥–µ–Ω—å
        weekday = now.weekday()
        hour = now.hour
        
        for event_name, event_info in MACRO_EVENTS.items():
            if weekday in event_info['typical_days']:
                for event_hour in event_info['typical_hours']:
                    if hour <= event_hour < hour + hours_ahead:
                        scheduled = now.replace(hour=event_hour, minute=0, second=0)
                        events.append(MacroEvent(
                            name=event_name,
                            description=event_info['description'],
                            scheduled_time=scheduled,
                            impact=NewsImpact[event_info['impact']]
                        ))
        
        return events
    
    def is_macro_event_window(self) -> Tuple[bool, Optional[str]]:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω–∞—Ö–æ–¥–∏–º—Å—è –ª–∏ –º—ã –≤ –æ–∫–Ω–µ –º–∞–∫—Ä–æ-—Å–æ–±—ã—Ç–∏—è"""
        now = datetime.now(timezone.utc)
        weekday = now.weekday()
        hour = now.hour
        
        for event_name, event_info in MACRO_EVENTS.items():
            if weekday in event_info['typical_days']:
                for event_hour in event_info['typical_hours']:
                    # –ó–∞ 30 –º–∏–Ω –¥–æ –∏ 30 –º–∏–Ω –ø–æ—Å–ª–µ
                    if event_hour - 1 <= hour <= event_hour + 1:
                        return True, event_name
        
        return False, None
    
    # ==================== SIGNAL GENERATION ====================
    
    def generate_trading_signal(self, event: NewsEvent) -> Optional[TradingSignal]:
        """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–æ—Ä–≥–æ–≤—ã–π —Å–∏–≥–Ω–∞–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤–æ—Å—Ç–∏"""
        
        # –§–∏–ª—å—Ç—Ä –ø–æ –∏–º–ø–∞–∫—Ç—É
        if event.impact.value < NewsImpact.MEDIUM.value:
            return None
        
        # –§–∏–ª—å—Ç—Ä –ø–æ confidence
        if event.confidence < 0.5:
            return None
        
        reasoning = []
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
        direction = None
        confidence = event.confidence
        
        if event.sentiment in [NewsSentiment.VERY_BULLISH, NewsSentiment.BULLISH]:
            direction = 'LONG'
            reasoning.append(f"üìà –ü–æ–∑–∏—Ç–∏–≤–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å: {event.sentiment.name}")
        elif event.sentiment in [NewsSentiment.VERY_BEARISH, NewsSentiment.BEARISH]:
            direction = 'SHORT'
            reasoning.append(f"üìâ –ù–µ–≥–∞—Ç–∏–≤–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å: {event.sentiment.name}")
        else:
            return None  # –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –Ω–µ —Ç–æ—Ä–≥—É–µ–º
        
        # –ú–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        if event.impact == NewsImpact.CRITICAL:
            confidence = min(0.95, confidence + 0.2)
            reasoning.append(f"‚ö° –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –≤–ª–∏—è–Ω–∏–µ")
        elif event.impact == NewsImpact.HIGH:
            confidence = min(0.9, confidence + 0.1)
            reasoning.append(f"üî• –í—ã—Å–æ–∫–æ–µ –≤–ª–∏—è–Ω–∏–µ")
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏—è
        reasoning.append(f"üìÅ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {event.category.value}")
        
        # –ò—Å—Ç–æ—á–Ω–∏–∫
        reasoning.append(f"üì∞ –ò—Å—Ç–æ—á–Ω–∏–∫: {event.source}")
        
        # –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ —Å–∏–≥–Ω–∞–ª–∞
        if event.category in [NewsCategory.MACRO, NewsCategory.REGULATION]:
            expires_delta = timedelta(hours=4)
            time_sensitive = True
        elif event.category == NewsCategory.HACK_EXPLOIT:
            expires_delta = timedelta(hours=1)
            time_sensitive = True
        else:
            expires_delta = timedelta(hours=2)
            time_sensitive = False
        
        return TradingSignal(
            direction=direction,
            confidence=confidence,
            source=event.source,
            reasoning=reasoning,
            affected_coins=event.affected_coins,
            time_sensitive=time_sensitive,
            expires_at=datetime.now(timezone.utc) + expires_delta,
            impact=event.impact
        )
    
    async def get_aggregated_signals(self) -> List[TradingSignal]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–æ—Ä–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        """
        all_events = []
        signals = []
        
        # –°–æ–±–∏—Ä–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        tasks = [
            self.fetch_cryptopanic_news(),        # CryptoPanic API
            self.fetch_twitter_sentiment(),        # RSS –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ –ª–µ–Ω—Ç—ã (CoinTelegraph, Decrypt, etc.)
            self.fetch_fear_greed_index(),         # Fear & Greed Index
            self.fetch_coingecko_trending(),       # Trending –Ω–∞ CoinGecko
            self.fetch_binance_announcements()     # –ê–Ω–æ–Ω—Å—ã Binance
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # CryptoPanic
        if isinstance(results[0], list):
            all_events.extend(results[0])
        
        # RSS News (CoinTelegraph, Decrypt, etc.)
        if isinstance(results[1], list):
            all_events.extend(results[1])
        
        # CoinGecko Trending
        if isinstance(results[3], list):
            all_events.extend(results[3])
        
        # Binance Announcements
        if isinstance(results[4], list):
            all_events.extend(results[4])
        
        # Fear & Greed –≤–ª–∏—è–µ—Ç –Ω–∞ –æ–±—â–∏–π —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç
        if isinstance(results[2], dict):
            fg = results[2]
            fg_value = fg.get('value', 50)
            
            if fg_value <= 25:  # Extreme Fear
                # –ö–æ–Ω—Ç—Ä-—Å–∏–≥–Ω–∞–ª: –ø–æ–∫—É–ø–∞–µ–º –Ω–∞ —Å—Ç—Ä–∞—Ö–µ
                signals.append(TradingSignal(
                    direction='LONG',
                    confidence=0.6,
                    source='Fear & Greed Index',
                    reasoning=[
                        f"üò± Extreme Fear: {fg_value}",
                        "–ö–æ–Ω—Ç—Ä-—Ç—Ä–µ–Ω–¥: –ø–æ–∫—É–ø–∫–∞ –Ω–∞ —Å—Ç—Ä–∞—Ö–µ",
                        f"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: {fg.get('classification')}"
                    ],
                    affected_coins=['BTC', 'ETH'],
                    time_sensitive=False,
                    expires_at=datetime.now(timezone.utc) + timedelta(hours=6),
                    impact=NewsImpact.MEDIUM
                ))
            elif fg_value >= 75:  # Extreme Greed
                # –ö–æ–Ω—Ç—Ä-—Å–∏–≥–Ω–∞–ª: –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç—å –Ω–∞ –∂–∞–¥–Ω–æ—Å—Ç–∏
                signals.append(TradingSignal(
                    direction='SHORT',
                    confidence=0.5,
                    source='Fear & Greed Index',
                    reasoning=[
                        f"ü§ë Extreme Greed: {fg_value}",
                        "–ö–æ–Ω—Ç—Ä-—Ç—Ä–µ–Ω–¥: –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç—å –Ω–∞ –∂–∞–¥–Ω–æ—Å—Ç–∏",
                        f"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: {fg.get('classification')}"
                    ],
                    affected_coins=['BTC', 'ETH'],
                    time_sensitive=False,
                    expires_at=datetime.now(timezone.utc) + timedelta(hours=6),
                    impact=NewsImpact.MEDIUM
                ))
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã –∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π
        for event in all_events:
            signal = self.generate_trading_signal(event)
            if signal:
                signals.append(signal)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ confidence –∏ impact
        signals.sort(key=lambda s: (s.impact.value, s.confidence), reverse=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–±—ã—Ç–∏—è
        for event in all_events:
            self.recent_events.append(event)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º market sentiment
        self._update_market_sentiment(all_events)
        
        logger.info(f"[NEWS] Generated {len(signals)} trading signals")
        return signals
    
    def _update_market_sentiment(self, events: List[NewsEvent]):
        """–û–±–Ω–æ–≤–∏—Ç—å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä—ã–Ω–æ—á–Ω—ã–π —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç"""
        if not events:
            return
        
        total_score = 0
        total_weight = 0
        
        for event in events:
            weight = event.impact.value * event.confidence
            score = event.sentiment.value * 25  # -50 to +50
            total_score += score * weight
            total_weight += weight
        
        if total_weight > 0:
            final_score = total_score / total_weight
            self.market_sentiment['score'] = max(-100, min(100, final_score))
            
            if final_score > 20:
                self.market_sentiment['trend'] = 'BULLISH'
            elif final_score < -20:
                self.market_sentiment['trend'] = 'BEARISH'
            else:
                self.market_sentiment['trend'] = 'NEUTRAL'
            
            self.market_sentiment['last_update'] = datetime.now(timezone.utc)
    
    def get_market_sentiment(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π —Ä—ã–Ω–æ—á–Ω—ã–π —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç"""
        return self.market_sentiment.copy()
    
    # ==================== MANIPULATION DETECTION ====================
    
    async def detect_manipulation_news(self) -> List[Dict]:
        """
        –î–µ—Ç–µ–∫—Ü–∏—è –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞:
        1. –í–Ω–µ–∑–∞–ø–Ω—ã–π –ø–æ—Ç–æ–∫ FUD
        2. –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ pump-–ø–æ—Å—Ç—ã
        3. –§–µ–π–∫–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
        """
        alerts = []
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è
        recent = list(self.recent_events)[-50:]
        
        if len(recent) < 5:
            return alerts
        
        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ FUD-–∞—Ç–∞–∫—É (–º–Ω–æ–≥–æ –Ω–µ–≥–∞—Ç–∏–≤–∞ –∑–∞ –∫–æ—Ä–æ—Ç–∫–æ–µ –≤—Ä–µ–º—è)
        last_hour = datetime.now(timezone.utc) - timedelta(hours=1)
        recent_negative = [e for e in recent 
                          if e.timestamp > last_hour 
                          and e.sentiment.value < 0]
        
        if len(recent_negative) >= 5:
            alerts.append({
                'type': 'FUD_ATTACK',
                'severity': 'HIGH',
                'description': f'–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(recent_negative)} –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ —á–∞—Å',
                'recommendation': '–í–æ–∑–º–æ–∂–Ω–∞—è –º–∞–Ω–∏–ø—É–ª—è—Ü–∏—è. –ù–µ –ø–∞–Ω–∏–∫–æ–≤–∞—Ç—å, –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏.'
            })
        
        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ pump-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—é
        recent_positive = [e for e in recent 
                          if e.timestamp > last_hour 
                          and e.sentiment.value > 0
                          and e.category == NewsCategory.TRADER_CALL]
        
        if len(recent_positive) >= 3:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≥–æ–≤–æ—Ä—è—Ç –ª–∏ –æ –æ–¥–Ω–æ–π –º–æ–Ω–µ—Ç–µ
            coin_counts = {}
            for e in recent_positive:
                for coin in e.affected_coins:
                    coin_counts[coin] = coin_counts.get(coin, 0) + 1
            
            for coin, count in coin_counts.items():
                if count >= 3:
                    alerts.append({
                        'type': 'COORDINATED_PUMP',
                        'severity': 'MEDIUM',
                        'description': f'{count} —Ç—Ä–µ–π–¥–µ—Ä–æ–≤ –≥–æ–≤–æ—Ä—è—Ç –æ {coin}',
                        'recommendation': f'–í–æ–∑–º–æ–∂–Ω—ã–π pump {coin}. –û—Å—Ç–æ—Ä–æ–∂–Ω–æ —Å –≤—Ö–æ–¥–æ–º.'
                    })
        
        return alerts
    
    # ==================== API FUNCTIONS ====================
    
    async def get_news_for_coin(self, coin: str) -> List[NewsEvent]:
        """–ü–æ–ª—É—á–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–Ω–µ—Ç—ã"""
        all_events = list(self.recent_events)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –º–æ–Ω–µ—Ç–µ
        coin_upper = coin.upper().replace('USDT', '').replace('/USDT', '')
        
        relevant = [e for e in all_events if coin_upper in e.affected_coins]
        
        return sorted(relevant, key=lambda x: x.timestamp, reverse=True)[:10]
    
    async def should_avoid_trading(self) -> Tuple[bool, Optional[str]]:
        """
        –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —Å—Ç–æ–∏—Ç –ª–∏ –∏–∑–±–µ–≥–∞—Ç—å —Ç–æ—Ä–≥–æ–≤–ª–∏ —Å–µ–π—á–∞—Å
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (should_avoid, reason)
        """
        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∞–∫—Ä–æ-—Å–æ–±—ã—Ç–∏—è
        is_macro, macro_event = self.is_macro_event_window()
        if is_macro:
            return True, f"–û–∫–Ω–æ –º–∞–∫—Ä–æ-—Å–æ–±—ã—Ç–∏—è: {macro_event}"
        
        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏
        manipulations = await self.detect_manipulation_news()
        if any(m['severity'] == 'HIGH' for m in manipulations):
            return True, "–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –≤–æ–∑–º–æ–∂–Ω–∞—è –º–∞–Ω–∏–ø—É–ª—è—Ü–∏—è"
        
        # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º extreme sentiment
        sentiment = self.get_market_sentiment()
        if abs(sentiment['score']) > 80:
            return False, f"‚ö†Ô∏è –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–π —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç: {sentiment['score']}"
        
        return False, None


# ==================== –ì–õ–û–ë–ê–õ–¨–ù–´–ô –≠–ö–ó–ï–ú–ü–õ–Ø–† ====================

news_analyzer = NewsAnalyzer()


# ==================== API –§–£–ù–ö–¶–ò–ò ====================

async def get_news_signals() -> List[TradingSignal]:
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–æ—Ä–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤–æ—Å—Ç–µ–π"""
    return await news_analyzer.get_aggregated_signals()


async def get_market_sentiment() -> Dict:
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π —Ä—ã–Ω–æ—á–Ω—ã–π —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç"""
    # –û–±–Ω–æ–≤–ª—è–µ–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if not news_analyzer.market_sentiment.get('last_update'):
        await news_analyzer.get_aggregated_signals()
    return news_analyzer.get_market_sentiment()


async def get_news_for_coin(coin: str) -> List[NewsEvent]:
    """–ü–æ–ª—É—á–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –º–æ–Ω–µ—Ç—ã"""
    return await news_analyzer.get_news_for_coin(coin)


async def should_trade_now() -> Tuple[bool, Optional[str]]:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –º–æ–∂–Ω–æ –ª–∏ —Ç–æ—Ä–≥–æ–≤–∞—Ç—å —Å–µ–π—á–∞—Å"""
    should_avoid, reason = await news_analyzer.should_avoid_trading()
    return not should_avoid, reason


async def get_upcoming_events() -> List[MacroEvent]:
    """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å—Ç–æ—è—â–∏–µ –º–∞–∫—Ä–æ-—Å–æ–±—ã—Ç–∏—è"""
    return news_analyzer.get_upcoming_macro_events()


async def detect_manipulations() -> List[Dict]:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏"""
    return await news_analyzer.detect_manipulation_news()


# ==================== –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –° SMART ANALYZER ====================

async def enhance_setup_with_news(setup: Any, coin: str) -> Any:
    """
    –£–ª—É—á—à–∏—Ç—å —Ç–æ—Ä–≥–æ–≤—ã–π —Å–µ—Ç–∞–ø –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π
    
    Args:
        setup: TradeSetup –æ–±—ä–µ–∫—Ç –∏–∑ smart_analyzer
        coin: –°–∏–º–≤–æ–ª –º–æ–Ω–µ—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä 'BTC')
    
    Returns:
        –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π setup —Å —É—á—ë—Ç–æ–º –Ω–æ–≤–æ—Å—Ç–µ–π
    """
    if setup is None:
        return None
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –º–æ–Ω–µ—Ç—ã
        news_events = await get_news_for_coin(coin)
        
        if not news_events:
            return setup
        
        # –°—á–∏—Ç–∞–µ–º —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
        bullish_count = sum(1 for e in news_events[:5] if e.sentiment.value > 0)
        bearish_count = sum(1 for e in news_events[:5] if e.sentiment.value < 0)
        
        # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º confidence
        setup_direction = setup.direction.upper()
        
        if setup_direction == 'LONG' and bullish_count > bearish_count:
            # –ù–æ–≤–æ—Å—Ç–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç –ª–æ–Ω–≥
            boost = min(0.1, bullish_count * 0.02)
            setup.confidence = min(0.95, setup.confidence + boost)
            setup.reasoning.insert(0, f"üì∞ –ù–æ–≤–æ—Å—Ç–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç ({bullish_count} –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö)")
            logger.info(f"[NEWS] {coin}: News boost +{boost:.0%} for LONG")
            
        elif setup_direction == 'SHORT' and bearish_count > bullish_count:
            # –ù–æ–≤–æ—Å—Ç–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç —à–æ—Ä—Ç
            boost = min(0.1, bearish_count * 0.02)
            setup.confidence = min(0.95, setup.confidence + boost)
            setup.reasoning.insert(0, f"üì∞ –ù–æ–≤–æ—Å—Ç–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç ({bearish_count} –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö)")
            logger.info(f"[NEWS] {coin}: News boost +{boost:.0%} for SHORT")
            
        elif (setup_direction == 'LONG' and bearish_count > bullish_count + 2) or \
             (setup_direction == 'SHORT' and bullish_count > bearish_count + 2):
            # –ù–æ–≤–æ—Å—Ç–∏ –ü–†–û–¢–ò–í–û–†–ï–ß–ê–¢ —Å–µ—Ç–∞–ø—É
            penalty = 0.1
            setup.confidence = max(0.3, setup.confidence - penalty)
            setup.reasoning.insert(0, f"‚ö†Ô∏è –ù–æ–≤–æ—Å—Ç–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∞—Ç —Å–µ—Ç–∞–ø—É")
            logger.warning(f"[NEWS] {coin}: News penalty -{penalty:.0%}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞–∂–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –≤ reasoning
        critical_news = [e for e in news_events[:3] if e.impact.value >= NewsImpact.HIGH.value]
        for news in critical_news[:2]:
            setup.reasoning.append(f"üì∞ {news.title[:50]}...")
        
    except Exception as e:
        logger.warning(f"[NEWS] Error enhancing setup: {e}")
    
    return setup


async def get_news_trading_opportunities() -> List[Dict]:
    """
    –ü–æ–ª—É—á–∏—Ç—å —Ç–æ—Ä–≥–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤–æ—Å—Ç–µ–π
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–¥–µ–ª–æ–∫
    """
    signals = await get_news_signals()
    
    opportunities = []
    
    for signal in signals[:5]:  # –¢–æ–ø-5 —Å–∏–≥–Ω–∞–ª–æ–≤
        if signal.confidence >= 0.6:
            opportunities.append({
                'direction': signal.direction,
                'coins': signal.affected_coins,
                'confidence': signal.confidence,
                'reasoning': signal.reasoning,
                'source': signal.source,
                'time_sensitive': signal.time_sensitive,
                'expires_at': signal.expires_at.isoformat()
            })
    
    return opportunities
