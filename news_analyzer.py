"""
News Analyzer v1.0 - –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π, Twitter –∏ –º–∞–∫—Ä–æ-—Å–æ–±—ã—Ç–∏–π –¥–ª—è —Ç—Ä–µ–π–¥–∏–Ω–≥–∞
–û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç: Trump, –∫—Ä—É–ø–Ω—ã—Ö —Ç—Ä–µ–π–¥–µ—Ä–æ–≤, –≥–æ—Å. –æ—Ä–≥–∞–Ω—ã –°–®–ê, –∫—Ä–∏–ø—Ç–æ-–Ω–æ–≤–æ—Å—Ç–∏

–§—É–Ω–∫—Ü–∏–∏:
1. Twitter/X –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–ª—é—á–µ–≤—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤
2. RSS/API –Ω–æ–≤–æ—Å—Ç–∏ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç
3. Macro-—Å–æ–±—ã—Ç–∏—è (FOMC, CPI, NFP, —Ç–∞—Ä–∏—Ñ—ã)
4. Sentiment –∞–Ω–∞–ª–∏–∑
5. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤–æ—Å—Ç–µ–π
"""

import asyncio
import aiohttp
import logging
import re
import json
import hashlib
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from enum import Enum
from collections import deque

logger = logging.getLogger(__name__)

# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ====================

# –ö–ª—é—á–µ–≤—ã–µ Twitter –∞–∫–∫–∞—É–Ω—Ç—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
TWITTER_ACCOUNTS = {
    # === –ü–û–õ–ò–¢–ò–ö–ò ===
    'realDonaldTrump': {
        'name': 'Donald Trump',
        'type': 'politician',
        'impact': 'HIGH',
        'keywords': ['crypto', 'bitcoin', 'tariff', 'china', 'economy', 'fed', 'rate', 'dollar', 'trade']
    },
    'POTUS': {
        'name': 'President of the United States',
        'type': 'government',
        'impact': 'HIGH',
        'keywords': ['economy', 'trade', 'tariff', 'crypto', 'digital', 'regulation']
    },
    'WhiteHouse': {
        'name': 'White House',
        'type': 'government',
        'impact': 'HIGH',
        'keywords': ['economy', 'executive order', 'trade', 'china', 'policy']
    },
    'USTreasury': {
        'name': 'US Treasury',
        'type': 'government',
        'impact': 'HIGH',
        'keywords': ['sanctions', 'dollar', 'debt', 'crypto', 'stablecoin', 'regulation']
    },
    'SECGov': {
        'name': 'SEC',
        'type': 'regulator',
        'impact': 'CRITICAL',
        'keywords': ['crypto', 'bitcoin', 'ethereum', 'enforcement', 'etf', 'regulation', 'lawsuit']
    },
    'federalreserve': {
        'name': 'Federal Reserve',
        'type': 'central_bank',
        'impact': 'CRITICAL',
        'keywords': ['rate', 'inflation', 'fomc', 'powell', 'monetary', 'balance sheet']
    },
    
    # === –¢–û–ü –ö–†–ò–ü–¢–û-–¢–†–ï–ô–î–ï–†–´ ===
    'CryptoCred': {
        'name': 'Crypto Cred',
        'type': 'trader',
        'impact': 'MEDIUM',
        'keywords': ['long', 'short', 'btc', 'eth', 'entry', 'target', 'stop']
    },
    'HsakaTrades': {
        'name': 'Hsaka',
        'type': 'trader',
        'impact': 'MEDIUM',
        'keywords': ['long', 'short', 'btc', 'eth', 'sol', 'position', 'tp', 'sl']
    },
    'CryptoKaleo': {
        'name': 'Kaleo',
        'type': 'trader',
        'impact': 'MEDIUM',
        'keywords': ['btc', 'eth', 'alt', 'degen', 'pump', 'moon']
    },
    'ColdBloodShill': {
        'name': 'ColdBloodShill',
        'type': 'trader',
        'impact': 'MEDIUM',
        'keywords': ['btc', 'eth', 'alts', 'chart', 'setup']
    },
    'inversebrah': {
        'name': 'InverseBrah',
        'type': 'trader',
        'impact': 'MEDIUM',
        'keywords': ['perp', 'long', 'short', 'liquidation', 'funding']
    },
    'GCRClassic': {
        'name': 'GCR',
        'type': 'trader',
        'impact': 'HIGH',
        'keywords': ['btc', 'macro', 'cycle', 'bear', 'bull']
    },
    'loomdart': {
        'name': 'Loomdart',
        'type': 'trader',
        'impact': 'MEDIUM',
        'keywords': ['btc', 'eth', 'trade', 'analysis']
    },
    'PeterLBrandt': {
        'name': 'Peter Brandt',
        'type': 'trader',
        'impact': 'MEDIUM',
        'keywords': ['btc', 'pattern', 'chart', 'target']
    },
    
    # === –ê–õ–¨–§–ê-–ì–†–£–ü–ü–´ –ò –°–ò–ì–ù–ê–õ–¨–ù–´–ï –ö–ê–ù–ê–õ–´ (–î–û–ë–ê–í–õ–ï–ù–û!) ===
    'MustStopMurad': {
        'name': 'Murad',
        'type': 'alpha',
        'impact': 'HIGH',
        'keywords': ['memecoin', 'meta', 'play', 'rotation', 'sol']
    },
    'blaborekek': {
        'name': 'Blknoiz06',
        'type': 'alpha',
        'impact': 'HIGH',
        'keywords': ['alpha', 'gem', 'early', 'narrative', 'meta']
    },
    'DefiIgnas': {
        'name': 'Ignas',
        'type': 'alpha',
        'impact': 'HIGH',
        'keywords': ['defi', 'yield', 'airdrop', 'strategy', 'alpha']
    },
    'Route2FI': {
        'name': 'Route2FI',
        'type': 'alpha',
        'impact': 'MEDIUM',
        'keywords': ['alpha', 'airdrop', 'strategy', 'yield']
    },
    'TheDeFinvestor': {
        'name': 'The DeFi Investor',
        'type': 'alpha',
        'impact': 'MEDIUM',
        'keywords': ['defi', 'yield', 'strategy', 'protocol']
    },
    'MilesDeutscher': {
        'name': 'Miles Deutscher',
        'type': 'alpha',
        'impact': 'HIGH',
        'keywords': ['narrative', 'rotation', 'alpha', 'gem', 'meta']
    },
    'AltcoinSherpa': {
        'name': 'Altcoin Sherpa',
        'type': 'trader',
        'impact': 'HIGH',
        'keywords': ['alt', 'chart', 'entry', 'setup', 'target']
    },
    'Pentosh1': {
        'name': 'Pentoshi',
        'type': 'trader',
        'impact': 'HIGH',
        'keywords': ['btc', 'long', 'short', 'macro', 'cycle']
    },
    'CryptoTony__': {
        'name': 'Crypto Tony',
        'type': 'trader',
        'impact': 'MEDIUM',
        'keywords': ['btc', 'eth', 'chart', 'analysis', 'setup']
    },
    'CryptoGodJohn': {
        'name': 'CryptoGodJohn',
        'type': 'alpha',
        'impact': 'HIGH',
        'keywords': ['memecoin', 'sol', 'degen', 'play', 'alpha']
    },
    'CryptoDonAlt': {
        'name': 'DonAlt',
        'type': 'trader',
        'impact': 'HIGH',
        'keywords': ['btc', 'macro', 'chart', 'cycle', 'bear', 'bull']
    },
    'crypto_birb': {
        'name': 'CryptoBirb',
        'type': 'trader',
        'impact': 'MEDIUM',
        'keywords': ['btc', 'eth', 'chart', 'pattern', 'target']
    },
    'SmartContracter': {
        'name': 'SmartContracter',
        'type': 'trader',
        'impact': 'HIGH',
        'keywords': ['btc', 'eth', 'setup', 'tp', 'sl', 'entry']
    },
    'CryptoCapo_': {
        'name': 'Capo',
        'type': 'trader',
        'impact': 'HIGH',
        'keywords': ['btc', 'macro', 'bear', 'bull', 'cycle']
    },
    'coaborekglass': {
        'name': 'Coinglass',
        'type': 'data',
        'impact': 'HIGH',
        'keywords': ['liquidation', 'funding', 'oi', 'long', 'short', 'ratio']
    },
    'LookOnChain': {
        'name': 'Lookonchain',
        'type': 'onchain',
        'impact': 'HIGH',
        'keywords': ['whale', 'transfer', 'deposit', 'withdraw', 'move']
    },
    'spoaborektonchain': {
        'name': 'Spot On Chain',
        'type': 'onchain',
        'impact': 'HIGH',
        'keywords': ['whale', 'wallet', 'transfer', 'accumulate', 'sell']
    },
    'EmberCN': {
        'name': 'Ember',
        'type': 'onchain',
        'impact': 'HIGH',
        'keywords': ['whale', 'smart money', 'flow', 'move']
    },
    'ai_9684xtpa': {
        'name': 'Ai_9684xtpa',
        'type': 'onchain',
        'impact': 'HIGH',
        'keywords': ['whale', 'deposit', 'withdraw', 'accumulate']
    },
    
    # === –ö–†–ò–ü–¢–û –ò–ù–°–ê–ô–î–ï–†–´ ===
    'caborek': {
        'name': 'Caborek',
        'type': 'insider',
        'impact': 'HIGH',
        'keywords': ['blackrock', 'etf', 'flow', 'institutional']
    },
    'WuBlockchain': {
        'name': 'Wu Blockchain',
        'type': 'news',
        'impact': 'HIGH',
        'keywords': ['china', 'mining', 'regulation', 'exchange', 'binance']
    },
    'FatManTerra': {
        'name': 'FatMan',
        'type': 'investigator',
        'impact': 'HIGH',
        'keywords': ['scam', 'fraud', 'warning', 'insolvency', 'hack']
    },
    'zachxbt': {
        'name': 'ZachXBT',
        'type': 'investigator',
        'impact': 'HIGH',
        'keywords': ['scam', 'hack', 'exploit', 'stolen', 'investigation']
    },
    
    # === –ë–ò–†–ñ–ò –ò –ü–†–û–ï–ö–¢–´ ===
    'binance': {
        'name': 'Binance',
        'type': 'exchange',
        'impact': 'HIGH',
        'keywords': ['listing', 'delist', 'maintenance', 'withdrawal', 'announcement']
    },
    'coinaborek': {
        'name': 'Coinbase',
        'type': 'exchange',
        'impact': 'HIGH',
        'keywords': ['listing', 'sec', 'legal', 'announcement']
    },
    'caborek': {
        'name': 'Grayscale',
        'type': 'fund',
        'impact': 'HIGH',
        'keywords': ['btc', 'eth', 'outflow', 'inflow', 'etf']
    },
    
    # === –≠–ö–û–ù–û–ú–ò–ö–ê ===
    'elaborianmusk': {
        'name': 'Elon Musk',
        'type': 'influencer',
        'impact': 'HIGH',
        'keywords': ['doge', 'bitcoin', 'crypto', 'tesla']
    },
    'michaeljsaylor': {
        'name': 'Michael Saylor',
        'type': 'bitcoin_bull',
        'impact': 'MEDIUM',
        'keywords': ['bitcoin', 'btc', 'microstrategy', 'buy', 'acquisition']
    }
}

# –ö—Ä–∏–ø—Ç–æ-—Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
BULLISH_KEYWORDS = [
    'bullish', 'moon', 'pump', 'breakout', 'ath', 'new high', 'adoption',
    'institutional', 'etf approved', 'blackrock', 'buy', 'long', 'accumulate',
    'bottom', 'reversal', 'support holding', 'green', 'rally', 'surge',
    'approval', 'partnership', 'integration', 'listing', 'mainnet', 'upgrade'
]

BEARISH_KEYWORDS = [
    'bearish', 'dump', 'crash', 'breakdown', 'new low', 'ban', 'regulation',
    'lawsuit', 'sec', 'enforcement', 'sell', 'short', 'distribute',
    'top', 'resistance', 'rejection', 'red', 'plunge', 'collapse',
    'hack', 'exploit', 'scam', 'insolvency', 'bankruptcy', 'delisting',
    'tariff', 'sanctions', 'war', 'recession'
]

NEUTRAL_HIGH_IMPACT = [
    'fomc', 'fed', 'cpi', 'nfp', 'gdp', 'inflation', 'rate decision',
    'powell', 'yellen', 'trump', 'executive order', 'announcement'
]

# –ú–∞–∫—Ä–æ-—Å–æ–±—ã—Ç–∏—è –∫–∞–ª–µ–Ω–¥–∞—Ä—å (UTC)
MACRO_EVENTS = {
    'FOMC': {
        'impact': 'CRITICAL',
        'typical_days': [2, 3],  # Wed-Thu
        'typical_hours': [18, 19],  # 6-7 PM UTC
        'description': 'Federal Reserve Rate Decision'
    },
    'CPI': {
        'impact': 'CRITICAL',
        'typical_days': list(range(7)),  # Any day
        'typical_hours': [12, 13],  # 12-1 PM UTC
        'description': 'Consumer Price Index'
    },
    'NFP': {
        'impact': 'HIGH',
        'typical_days': [4],  # Friday
        'typical_hours': [12, 13],
        'description': 'Non-Farm Payrolls'
    },
    'GDP': {
        'impact': 'HIGH',
        'typical_days': list(range(7)),
        'typical_hours': [12, 13],
        'description': 'Gross Domestic Product'
    },
    'PCE': {
        'impact': 'HIGH',
        'typical_days': list(range(7)),
        'typical_hours': [12, 13],
        'description': 'Personal Consumption Expenditures'
    }
}

# News APIs
NEWS_SOURCES = {
    'cryptopanic': 'https://cryptopanic.com/api/v1/posts/?auth_token={api_key}&currencies=BTC,ETH,SOL&filter=hot',
    'coingecko_news': 'https://api.coingecko.com/api/v3/status_updates',
    'fear_greed': 'https://api.alternative.me/fng/?limit=1'
}

# === COINGLASS API (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã) ===
COINGLASS_ENDPOINTS = {
    'funding_rates': 'https://open-api.coinglass.com/public/v2/funding',
    'liquidation_24h': 'https://open-api.coinglass.com/public/v2/liquidation_chart',
    'long_short_ratio': 'https://open-api.coinglass.com/public/v2/long_short_ratio',
    'open_interest': 'https://open-api.coinglass.com/public/v2/open_interest',
}

# DexScreener –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ö–∞–π–ø–∞ –Ω–∞ DEX
DEXSCREENER_API = 'https://api.dexscreener.com/latest/dex'

# RSS.app API –¥–ª—è Twitter —Ñ–∏–¥–æ–≤
RSS_APP_API_KEY = "c_xMtGIIcrdOZ8Nt"
RSS_APP_API_SECRET = "s_r8NiIDkqNcLUwMDiusRtqf"
RSS_APP_API_URL = "https://api.rss.app/v1"
RSS_APP_BUNDLE_ID = "_XzgeXtiahhlT8Vg5"  # YULA bundle —Å Twitter –∞–∫–∫–∞—É–Ω—Ç–∞–º–∏

# –ö—ç—à —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö —Ñ–∏–¥–æ–≤ RSS.app {username: feed_id}
_rss_app_feeds_cache = {}

# –ö—ç—à —Ä–∞–±–æ—Ç–∞—é—â–µ–≥–æ RSSHub –∏–Ω—Å—Ç–∞–Ω—Å–∞
_working_rsshub_instance = None
_rsshub_last_check = None

# RSSHub instances –¥–ª—è Twitter
RSSHUB_INSTANCES = [
    'https://rsshub.app',
    'https://rss.shab.fun',
    'https://rsshub.rssforever.com',
]

# –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –∞–∫–∫–∞—É–Ω—Ç—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ (—Å–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ)
PRIORITY_TWITTER_ACCOUNTS = [
    'realDonaldTrump', 'POTUS', 'SECGov', 'federalreserve',  # –ü–æ–ª–∏—Ç–∏–∫–∞/—Ä–µ–≥—É–ª—è—Ç–æ—Ä—ã
    'elonmusk', 'michaeljsaylor',  # –ö—Ä–∏–ø—Ç–æ-–∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä—ã
    'binance', 'caborek',  # –ë–∏—Ä–∂–∏
    'zachxbt', 'WuBlockchain',  # –ò–Ω—Å–∞–π–¥–µ—Ä—ã
    'Pentosh1', 'CryptoDonAlt', 'GCRClassic', 'AltcoinSherpa',  # –¢–æ–ø —Ç—Ä–µ–π–¥–µ—Ä—ã
    'LookOnChain', 'EmberCN', 'ai_9684xtpa',  # On-chain –∞–Ω–∞–ª–∏—Ç–∏–∫–∞
    'DefiIgnas', 'MilesDeutscher', 'MustStopMurad',  # –ê–ª—å—Ñ–∞
]

# –ü–æ—Ä–æ–≥–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Å–∏–≥–Ω–∞–ª–æ–≤
COINGLASS_THRESHOLDS = {
    'extreme_funding_long': 0.05,    # >0.05% = –ø–µ—Ä–µ–≥—Ä–µ–≤ –ª–æ–Ω–≥–æ–≤
    'extreme_funding_short': -0.03,  # <-0.03% = –ø–µ—Ä–µ–≥—Ä–µ–≤ —à–æ—Ä—Ç–æ–≤
    'liquidation_spike': 50_000_000,  # >$50M –ª–∏–∫–≤–∏–¥–∞—Ü–∏–π = –≤–æ–∑–º–æ–∂–Ω—ã–π —Ä–∞–∑–≤–æ—Ä–æ—Ç
    'long_short_extreme_long': 70,    # >70% –ª–æ–Ω–≥–æ–≤ = –æ–ø–∞—Å–Ω–æ
    'long_short_extreme_short': 30,   # <30% –ª–æ–Ω–≥–æ–≤ = –≤–æ–∑–º–æ–∂–µ–Ω —à–æ—Ä—Ç-—Å–∫–≤–∏–∑
    'oi_change_significant': 5,       # >5% –∏–∑–º–µ–Ω–µ–Ω–∏–µ OI = –≤–∞–∂–Ω–æ
}


# ==================== –¢–ò–ü–´ –î–ê–ù–ù–´–• ====================

class NewsImpact(Enum):
    """–í–ª–∏—è–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –Ω–∞ —Ä—ã–Ω–æ–∫"""
    CRITICAL = 5  # –ú–æ–∂–µ—Ç –¥–≤–∏–Ω—É—Ç—å —Ä—ã–Ω–æ–∫ –Ω–∞ 5-10%+
    HIGH = 4      # 2-5% –¥–≤–∏–∂–µ–Ω–∏–µ
    MEDIUM = 3    # 1-2% –¥–≤–∏–∂–µ–Ω–∏–µ
    LOW = 2       # <1% –¥–≤–∏–∂–µ–Ω–∏–µ
    NOISE = 1     # –®—É–º, –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å


class NewsSentiment(Enum):
    """–°–µ–Ω—Ç–∏–º–µ–Ω—Ç –Ω–æ–≤–æ—Å—Ç–∏"""
    VERY_BULLISH = 2
    BULLISH = 1
    NEUTRAL = 0
    BEARISH = -1
    VERY_BEARISH = -2


class NewsCategory(Enum):
    """–ö–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–æ–≤–æ—Å—Ç–∏"""
    REGULATION = 'regulation'
    MACRO = 'macro'
    TARIFFS = 'tariffs'
    HACK_EXPLOIT = 'hack'
    LISTING = 'listing'
    PARTNERSHIP = 'partnership'
    WHALE_MOVE = 'whale'
    TRADER_CALL = 'trader_call'
    POLITICAL = 'political'
    TECHNICAL = 'technical'
    OTHER = 'other'


@dataclass
class NewsEvent:
    """–ù–æ–≤–æ—Å—Ç–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ"""
    id: str
    source: str
    author: str
    title: str
    content: str
    url: str
    timestamp: datetime
    sentiment: NewsSentiment
    impact: NewsImpact
    category: NewsCategory
    affected_coins: List[str]
    keywords_found: List[str]
    confidence: float  # 0-1
    trading_signal: Optional[str] = None  # 'LONG', 'SHORT', None
    reasoning: List[str] = field(default_factory=list)


@dataclass
class MacroEvent:
    """–ú–∞–∫—Ä–æ-—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–æ–µ —Å–æ–±—ã—Ç–∏–µ"""
    name: str
    description: str
    scheduled_time: datetime
    impact: NewsImpact
    actual_value: Optional[float] = None
    forecast_value: Optional[float] = None
    previous_value: Optional[float] = None
    surprise: Optional[float] = None  # actual - forecast


@dataclass
class TradingSignal:
    """–¢–æ—Ä–≥–æ–≤—ã–π —Å–∏–≥–Ω–∞–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤–æ—Å—Ç–µ–π"""
    direction: str  # 'LONG' –∏–ª–∏ 'SHORT'
    confidence: float  # 0-1
    source: str  # –ò—Å—Ç–æ—á–Ω–∏–∫ —Å–∏–≥–Ω–∞–ª–∞
    reasoning: List[str]
    affected_coins: List[str]
    time_sensitive: bool  # –ù—É–∂–Ω–æ –ª–∏ –¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ
    expires_at: datetime  # –ö–æ–≥–¥–∞ —Å–∏–≥–Ω–∞–ª –∏—Å—Ç–µ–∫–∞–µ—Ç
    impact: NewsImpact


# ==================== NEWS ANALYZER ====================

class NewsAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π –∏ Twitter –¥–ª—è —Ç—Ä–µ–π–¥–∏–Ω–≥–∞"""
    
    def __init__(self, cryptopanic_api_key: str = None):
        self.cryptopanic_key = cryptopanic_api_key
        
        # –ö—ç—à –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –¥—É–±–ª–µ–π
        self.seen_news: deque = deque(maxlen=1000)
        self.recent_events: deque = deque(maxlen=100)
        
        # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç
        self.market_sentiment = {
            'score': 0,  # -100 to +100
            'trend': 'NEUTRAL',  # BULLISH, BEARISH, NEUTRAL
            'last_update': None
        }
        
        # –ö—ç—à –¥–ª—è API
        self._cache: Dict[str, Tuple[Any, datetime]] = {}
        self._cache_ttl = 60  # —Å–µ–∫—É–Ω–¥
        
        logger.info("[NEWS] Analyzer initialized")
    
    def _get_news_hash(self, title: str, source: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ —Ö—ç—à–∞ –Ω–æ–≤–æ—Å—Ç–∏"""
        content = f"{title}:{source}".lower()
        return hashlib.md5(content.encode()).hexdigest()[:16]
    
    def _is_cached(self, key: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞"""
        if key in self._cache:
            data, timestamp = self._cache[key]
            if datetime.now() - timestamp < timedelta(seconds=self._cache_ttl):
                return True
        return False
    
    def _get_cached(self, key: str) -> Any:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–∑ –∫—ç—à–∞"""
        if key in self._cache:
            return self._cache[key][0]
        return None
    
    def _set_cache(self, key: str, value: Any):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –∫—ç—à"""
        self._cache[key] = (value, datetime.now())
    
    # ==================== SENTIMENT ANALYSIS ====================
    
    def analyze_sentiment(self, text: str) -> Tuple[NewsSentiment, float, List[str]]:
        """
        –ê–Ω–∞–ª–∏–∑ —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞ —Ç–µ–∫—Å—Ç–∞
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (sentiment, confidence, found_keywords)
        """
        text_lower = text.lower()
        found_keywords = []
        
        bullish_score = 0
        bearish_score = 0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±—ã—á—å–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        for keyword in BULLISH_KEYWORDS:
            if keyword in text_lower:
                bullish_score += 1
                found_keywords.append(f"‚úÖ {keyword}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ–¥–≤–µ–∂—å–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        for keyword in BEARISH_KEYWORDS:
            if keyword in text_lower:
                bearish_score += 1
                found_keywords.append(f"‚ùå {keyword}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –≤—ã—Å–æ–∫–æ-–∏–º–ø–∞–∫—Ç–Ω—ã–µ
        for keyword in NEUTRAL_HIGH_IMPACT:
            if keyword in text_lower:
                found_keywords.append(f"‚ö° {keyword}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç
        total_score = bullish_score - bearish_score
        total_keywords = bullish_score + bearish_score
        
        if total_keywords == 0:
            return NewsSentiment.NEUTRAL, 0.3, found_keywords
        
        confidence = min(0.9, 0.4 + (total_keywords * 0.1))
        
        if total_score >= 3:
            return NewsSentiment.VERY_BULLISH, confidence, found_keywords
        elif total_score >= 1:
            return NewsSentiment.BULLISH, confidence, found_keywords
        elif total_score <= -3:
            return NewsSentiment.VERY_BEARISH, confidence, found_keywords
        elif total_score <= -1:
            return NewsSentiment.BEARISH, confidence, found_keywords
        else:
            return NewsSentiment.NEUTRAL, confidence, found_keywords
    
    def detect_category(self, text: str, source: str) -> NewsCategory:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é –Ω–æ–≤–æ—Å—Ç–∏"""
        text_lower = text.lower()
        
        if any(w in text_lower for w in ['sec', 'regulation', 'lawsuit', 'enforcement', 'ban', 'legal']):
            return NewsCategory.REGULATION
        elif any(w in text_lower for w in ['fomc', 'fed', 'cpi', 'nfp', 'inflation', 'rate', 'powell']):
            return NewsCategory.MACRO
        elif any(w in text_lower for w in ['tariff', 'trade war', 'china', 'sanctions']):
            return NewsCategory.TARIFFS
        elif any(w in text_lower for w in ['hack', 'exploit', 'stolen', 'breach', 'vulnerability']):
            return NewsCategory.HACK_EXPLOIT
        elif any(w in text_lower for w in ['listing', 'delist', 'launch', 'mainnet']):
            return NewsCategory.LISTING
        elif any(w in text_lower for w in ['partnership', 'integration', 'collaboration']):
            return NewsCategory.PARTNERSHIP
        elif any(w in text_lower for w in ['whale', 'large transfer', 'moved', 'billion']):
            return NewsCategory.WHALE_MOVE
        elif source in ['trader'] or any(w in text_lower for w in ['long', 'short', 'entry', 'target']):
            return NewsCategory.TRADER_CALL
        elif any(w in text_lower for w in ['trump', 'biden', 'congress', 'senate', 'executive order']):
            return NewsCategory.POLITICAL
        else:
            return NewsCategory.OTHER
    
    def extract_coins(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á—å —É–ø–æ–º—è–Ω—É—Ç—ã–µ –º–æ–Ω–µ—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        coins = []
        text_upper = text.upper()
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–æ–Ω–µ—Ç—ã
        coin_patterns = [
            'BTC', 'BITCOIN', 'ETH', 'ETHEREUM', 'SOL', 'SOLANA',
            'XRP', 'RIPPLE', 'BNB', 'DOGE', 'DOGECOIN', 'ADA', 'CARDANO',
            'AVAX', 'DOT', 'MATIC', 'LINK', 'UNI', 'ATOM', 'LTC',
            'NEAR', 'APT', 'ARB', 'OP', 'SUI', 'SEI', 'INJ', 'TIA',
            'PEPE', 'SHIB', 'FLOKI', 'BONK', 'WIF', 'MEME',
            'FET', 'RNDR', 'TAO', 'WLD', 'ARKM'
        ]
        
        for pattern in coin_patterns:
            if pattern in text_upper:
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
                normalized = pattern.replace('BITCOIN', 'BTC').replace('ETHEREUM', 'ETH')
                normalized = normalized.replace('SOLANA', 'SOL').replace('RIPPLE', 'XRP')
                normalized = normalized.replace('DOGECOIN', 'DOGE').replace('CARDANO', 'ADA')
                if normalized not in coins:
                    coins.append(normalized)
        
        return coins if coins else ['BTC']  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é BTC
    
    def calculate_impact(self, source_type: str, category: NewsCategory, 
                         sentiment_strength: int) -> NewsImpact:
        """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å –≤–ª–∏—è–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏"""
        base_impact = 2  # LOW
        
        # –ü–æ –∏—Å—Ç–æ—á–Ω–∏–∫—É
        if source_type in ['regulator', 'central_bank']:
            base_impact = 5  # CRITICAL
        elif source_type in ['government', 'politician']:
            base_impact = 4  # HIGH
        elif source_type in ['exchange', 'investigator']:
            base_impact = 4  # HIGH
        elif source_type in ['trader', 'insider']:
            base_impact = 3  # MEDIUM
        
        # –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        if category in [NewsCategory.REGULATION, NewsCategory.MACRO]:
            base_impact = max(base_impact, 4)
        elif category in [NewsCategory.HACK_EXPLOIT, NewsCategory.TARIFFS]:
            base_impact = max(base_impact, 4)
        
        # –ü–æ —Å–∏–ª–µ —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞
        if abs(sentiment_strength) >= 2:
            base_impact = min(5, base_impact + 1)
        
        return NewsImpact(min(5, max(1, base_impact)))
    
    # ==================== NEWS FETCHING ====================
    
    async def fetch_cryptopanic_news(self) -> List[NewsEvent]:
        """–ü–æ–ª—É—á–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ —Å CryptoPanic"""
        if not self.cryptopanic_key:
            return []
        
        cache_key = 'cryptopanic'
        if self._is_cached(cache_key):
            return self._get_cached(cache_key)
        
        events = []
        
        try:
            url = f"https://cryptopanic.com/api/v1/posts/?auth_token={self.cryptopanic_key}&filter=hot&public=true"
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=aiohttp.ClientTimeout(total=10)) as resp:
                    if resp.status != 200:
                        return events
                    
                    data = await resp.json()
            
            for post in data.get('results', [])[:20]:
                title = post.get('title', '')
                news_hash = self._get_news_hash(title, 'cryptopanic')
                
                if news_hash in self.seen_news:
                    continue
                
                self.seen_news.append(news_hash)
                
                sentiment, confidence, keywords = self.analyze_sentiment(title)
                category = self.detect_category(title, 'news')
                coins = self.extract_coins(title)
                impact = self.calculate_impact('news', category, sentiment.value)
                
                event = NewsEvent(
                    id=news_hash,
                    source='CryptoPanic',
                    author=post.get('source', {}).get('title', 'Unknown'),
                    title=title,
                    content=title,
                    url=post.get('url', ''),
                    timestamp=datetime.fromisoformat(post.get('created_at', '').replace('Z', '+00:00')),
                    sentiment=sentiment,
                    impact=impact,
                    category=category,
                    affected_coins=coins,
                    keywords_found=keywords,
                    confidence=confidence
                )
                
                events.append(event)
            
            self._set_cache(cache_key, events)
            logger.info(f"[NEWS] Fetched {len(events)} news from CryptoPanic")
            
        except Exception as e:
            logger.warning(f"[NEWS] CryptoPanic error: {e}")
        
        return events
    
    async def fetch_fear_greed_index(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω–¥–µ–∫—Å —Å—Ç—Ä–∞—Ö–∞ –∏ –∂–∞–¥–Ω–æ—Å—Ç–∏"""
        cache_key = 'fear_greed'
        if self._is_cached(cache_key):
            return self._get_cached(cache_key)
        
        result = {
            'value': 50,
            'classification': 'Neutral',
            'timestamp': datetime.now(timezone.utc)
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    'https://api.alternative.me/fng/?limit=1',
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        if data.get('data'):
                            fg = data['data'][0]
                            result['value'] = int(fg.get('value', 50))
                            result['classification'] = fg.get('value_classification', 'Neutral')
            
            self._set_cache(cache_key, result)
            logger.info(f"[NEWS] Fear & Greed: {result['value']} ({result['classification']})")
            
        except Exception as e:
            logger.warning(f"[NEWS] Fear & Greed error: {e}")
        
        return result
    
    async def fetch_twitter_sentiment(self, accounts: List[str] = None) -> List[NewsEvent]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∫—Ä–∏–ø—Ç–æ-–Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –†–ê–ë–û–¢–ê–Æ–©–ò–• –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:
        1. CoinTelegraph RSS
        2. Decrypt RSS
        3. TheBlock RSS
        4. Bitcoin Magazine RSS
        5. CryptoSlate RSS
        """
        events = []
        
        # –†–∞–±–æ—Ç–∞—é—â–∏–µ RSS –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∫—Ä–∏–ø—Ç–æ-–Ω–æ–≤–æ—Å—Ç–µ–π
        rss_sources = [
            {
                'url': 'https://cointelegraph.com/rss',
                'name': 'CoinTelegraph',
                'type': 'news',
                'impact': 'HIGH'
            },
            {
                'url': 'https://decrypt.co/feed',
                'name': 'Decrypt',
                'type': 'news',
                'impact': 'HIGH'
            },
            {
                'url': 'https://www.theblock.co/rss.xml',
                'name': 'TheBlock',
                'type': 'news',
                'impact': 'HIGH'
            },
            {
                'url': 'https://bitcoinmagazine.com/.rss/full/',
                'name': 'Bitcoin Magazine',
                'type': 'news',
                'impact': 'MEDIUM'
            },
            {
                'url': 'https://cryptoslate.com/feed/',
                'name': 'CryptoSlate',
                'type': 'news',
                'impact': 'MEDIUM'
            },
            {
                'url': 'https://www.coindesk.com/arc/outboundfeeds/rss/',
                'name': 'CoinDesk',
                'type': 'news',
                'impact': 'HIGH'
            }
        ]
        
        for source in rss_sources:
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(
                        source['url'],
                        timeout=aiohttp.ClientTimeout(total=10),
                        headers={
                            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                            'Accept': 'application/rss+xml, application/xml, text/xml'
                        }
                    ) as resp:
                        if resp.status != 200:
                            logger.debug(f"[NEWS] {source['name']} returned {resp.status}")
                            continue
                        
                        content = await resp.text()
                
                # –ü–∞—Ä—Å–∏–º RSS
                items = re.findall(r'<item>(.*?)</item>', content, re.DOTALL | re.IGNORECASE)
                
                if not items:
                    # –ü–æ–ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (Atom)
                    items = re.findall(r'<entry>(.*?)</entry>', content, re.DOTALL | re.IGNORECASE)
                
                for item in items[:10]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –Ω–æ–≤–æ—Å—Ç–µ–π
                    # –ü–∞—Ä—Å–∏–º title
                    title_match = re.search(r'<title[^>]*>(.*?)</title>', item, re.DOTALL)
                    if not title_match:
                        continue
                    
                    title = title_match.group(1)
                    title = re.sub(r'<!\[CDATA\[(.*?)\]\]>', r'\1', title)  # –£–±–∏—Ä–∞–µ–º CDATA
                    title = re.sub(r'<[^>]+>', '', title)  # –£–±–∏—Ä–∞–µ–º HTML —Ç–µ–≥–∏
                    title = title.strip()
                    
                    if not title or len(title) < 10:
                        continue
                    
                    news_hash = self._get_news_hash(title, source['name'])
                    if news_hash in self.seen_news:
                        continue
                    
                    self.seen_news.append(news_hash)
                    
                    # –ü–∞—Ä—Å–∏–º —Å—Å—ã–ª–∫—É
                    link_match = re.search(r'<link[^>]*>([^<]+)</link>', item)
                    if not link_match:
                        link_match = re.search(r'<link[^>]*href=["\']([^"\']+)["\']', item)
                    url = link_match.group(1) if link_match else ''
                    
                    # –ü–∞—Ä—Å–∏–º –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                    desc_match = re.search(r'<description[^>]*>(.*?)</description>', item, re.DOTALL)
                    description = ''
                    if desc_match:
                        description = re.sub(r'<!\[CDATA\[(.*?)\]\]>', r'\1', desc_match.group(1))
                        description = re.sub(r'<[^>]+>', '', description)[:200]
                    
                    # –ê–Ω–∞–ª–∏–∑
                    full_text = f"{title} {description}"
                    sentiment, confidence, keywords = self.analyze_sentiment(full_text)
                    category = self.detect_category(full_text, source['type'])
                    coins = self.extract_coins(full_text)
                    impact = self.calculate_impact(source['type'], category, sentiment.value)
                    
                    # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É
                    timestamp = datetime.now(timezone.utc)
                    date_match = re.search(r'<pubDate>(.*?)</pubDate>', item)
                    if not date_match:
                        date_match = re.search(r'<published>(.*?)</published>', item)
                    if date_match:
                        try:
                            from email.utils import parsedate_to_datetime
                            timestamp = parsedate_to_datetime(date_match.group(1))
                        except:
                            try:
                                # ISO format fallback
                                timestamp = datetime.fromisoformat(date_match.group(1).replace('Z', '+00:00'))
                            except:
                                pass
                    
                    event = NewsEvent(
                        id=news_hash,
                        source=source['name'],
                        author=source['name'],
                        title=title[:200],
                        content=description or title,
                        url=url,
                        timestamp=timestamp,
                        sentiment=sentiment,
                        impact=impact,
                        category=category,
                        affected_coins=coins,
                        keywords_found=keywords,
                        confidence=confidence
                    )
                    
                    events.append(event)
                
                logger.debug(f"[NEWS] {source['name']}: parsed {len(items)} items")
                
            except Exception as e:
                logger.debug(f"[NEWS] {source['name']} error: {e}")
                continue
            
            await asyncio.sleep(0.3)  # Rate limiting
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        events.sort(key=lambda x: x.timestamp, reverse=True)
        
        logger.info(f"[NEWS] Fetched {len(events)} news from RSS sources")
        return events
    
    async def fetch_twitter_posts(self, accounts: List[str] = None) -> List[NewsEvent]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Ç–≤–∏—Ç—ã –æ—Ç –∫–ª—é—á–µ–≤—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ RSS.app API
        Fallback: RSSHub
        """
        events = []
        accounts_to_fetch = accounts or PRIORITY_TWITTER_ACCOUNTS[:8]  # –¢–æ–ø 8 –∞–∫–∫–∞—É–Ω—Ç–æ–≤
        logger.info(f"[TWITTER] Starting fetch for {len(accounts_to_fetch)} accounts: {accounts_to_fetch[:3]}...")
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º RSS.app API
        try:
            rss_app_events = await self._fetch_twitter_via_rss_app(accounts_to_fetch)
            if rss_app_events:
                logger.info(f"[TWITTER] ‚úÖ Got {len(rss_app_events)} tweets via RSS.app")
                return rss_app_events
            else:
                logger.warning("[TWITTER] RSS.app returned empty list")
        except Exception as e:
            logger.warning(f"[TWITTER] RSS.app failed: {e}")
        
        # Fallback –Ω–∞ RSSHub
        global _working_rsshub_instance, _rsshub_last_check
        working_instance = None
        now = datetime.now()
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω—Å—Ç–∞–Ω—Å –µ—Å–ª–∏ –ø—Ä–æ–≤–µ—Ä—è–ª–∏ –Ω–µ–¥–∞–≤–Ω–æ
        if _working_rsshub_instance and _rsshub_last_check:
            if (now - _rsshub_last_check).total_seconds() < 300:
                working_instance = _working_rsshub_instance
        
        async with aiohttp.ClientSession() as session:
            # –ò—â–µ–º —Ä–∞–±–æ—Ç–∞—é—â–∏–π RSSHub –∏–Ω—Å—Ç–∞–Ω—Å
            if not working_instance:
                for instance in RSSHUB_INSTANCES:
                    try:
                        test_url = f"{instance}/twitter/user/elonmusk"
                        async with session.get(
                            test_url,
                            timeout=aiohttp.ClientTimeout(total=8),
                            headers={'User-Agent': 'Mozilla/5.0', 'Accept': '*/*'},
                            allow_redirects=True
                        ) as resp:
                            if resp.status == 200:
                                content = await resp.text()
                                if '<item>' in content or '<entry>' in content:
                                    working_instance = instance
                                    _working_rsshub_instance = instance
                                    _rsshub_last_check = now
                                    logger.info(f"[TWITTER] ‚úÖ Found working RSSHub: {instance}")
                                    break
                    except Exception as e:
                        logger.debug(f"[TWITTER] {instance} failed: {e}")
                        continue
            
            if not working_instance:
                logger.warning("[TWITTER] ‚ùå No working RSSHub instance found")
                return events
            
            # –ü–∞—Ä—Å–∏–º —Ç–≤–∏—Ç—ã –æ—Ç –∫–∞–∂–¥–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞ —á–µ—Ä–µ–∑ RSSHub
            for username in accounts_to_fetch:
                try:
                    rss_url = f"{working_instance}/twitter/user/{username}"
                    
                    async with session.get(
                        rss_url,
                        timeout=aiohttp.ClientTimeout(total=10),
                        headers={
                            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                            'Accept': 'application/rss+xml, application/xml, text/xml'
                        }
                    ) as resp:
                        if resp.status != 200:
                            continue
                        
                        content = await resp.text()
                    
                    # –ü–∞—Ä—Å–∏–º RSS
                    items = re.findall(r'<item>(.*?)</item>', content, re.DOTALL | re.IGNORECASE)
                    
                    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–∫–∫–∞—É–Ω—Ç–µ
                    account_info = TWITTER_ACCOUNTS.get(username, {
                        'name': username,
                        'type': 'unknown',
                        'impact': 'MEDIUM',
                        'keywords': []
                    })
                    
                    for item in items[:5]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Ç–≤–∏—Ç–æ–≤ –æ—Ç –∫–∞–∂–¥–æ–≥–æ
                        # –ü–∞—Ä—Å–∏–º title (—Ç–µ–∫—Å—Ç —Ç–≤–∏—Ç–∞)
                        title_match = re.search(r'<title[^>]*>(.*?)</title>', item, re.DOTALL)
                        if not title_match:
                            continue
                        
                        title = title_match.group(1)
                        title = re.sub(r'<!\[CDATA\[(.*?)\]\]>', r'\1', title)
                        title = re.sub(r'<[^>]+>', '', title)
                        title = title.strip()
                        
                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º RT: –∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ
                        if not title or len(title) < 15 or title.startswith('RT:'):
                            continue
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –∞–∫–∫–∞—É–Ω—Ç–∞
                        account_keywords = account_info.get('keywords', [])
                        is_relevant = False
                        
                        title_lower = title.lower()
                        # –í—Å–µ–≥–¥–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ –µ—Å–ª–∏ –æ—Ç –≤–∞–∂–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
                        if account_info.get('type') in ['regulator', 'central_bank', 'government', 'politician']:
                            is_relevant = True
                        # –ò–ª–∏ –µ—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
                        elif any(kw.lower() in title_lower for kw in account_keywords):
                            is_relevant = True
                        # –ò–ª–∏ –æ–±—â–∏–µ –∫—Ä–∏–ø—Ç–æ-–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
                        elif any(kw in title_lower for kw in ['btc', 'bitcoin', 'eth', 'crypto', 'sol', 'pump', 'dump', 'long', 'short']):
                            is_relevant = True
                        
                        if not is_relevant:
                            continue
                        
                        news_hash = self._get_news_hash(title, f"twitter_{username}")
                        if news_hash in self.seen_news:
                            continue
                        
                        self.seen_news.append(news_hash)
                        
                        # –ü–∞—Ä—Å–∏–º —Å—Å—ã–ª–∫—É
                        link_match = re.search(r'<link[^>]*>([^<]+)</link>', item)
                        url = link_match.group(1).strip() if link_match else f"https://twitter.com/{username}"
                        # –ó–∞–º–µ–Ω—è–µ–º rsshub URL –Ω–∞ twitter
                        url = re.sub(r'https?://rsshub[^/]*/twitter/user/', 'https://twitter.com/', url)
                        
                        # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É
                        timestamp = datetime.now(timezone.utc)
                        date_match = re.search(r'<pubDate>(.*?)</pubDate>', item)
                        if date_match:
                            try:
                                from email.utils import parsedate_to_datetime
                                timestamp = parsedate_to_datetime(date_match.group(1))
                            except:
                                pass
                        
                        # –ê–Ω–∞–ª–∏–∑ —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞
                        sentiment, confidence, keywords = self.analyze_sentiment(title)
                        category = self.detect_category(title, account_info.get('type', 'trader'))
                        coins = self.extract_coins(title)
                        
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º impact –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ –∞–∫–∫–∞—É–Ω—Ç–∞
                        impact_str = account_info.get('impact', 'MEDIUM')
                        try:
                            base_impact = NewsImpact[impact_str]
                        except KeyError:
                            base_impact = NewsImpact.MEDIUM
                        
                        # Boost confidence –¥–ª—è –≤–∞–∂–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
                        if account_info.get('type') in ['regulator', 'central_bank', 'government']:
                            confidence = min(0.95, confidence + 0.2)
                        elif account_info.get('type') in ['politician', 'exchange']:
                            confidence = min(0.9, confidence + 0.1)
                        
                        event = NewsEvent(
                            id=news_hash,
                            source=f"üê¶ @{username}",
                            author=account_info.get('name', username),
                            title=title[:200],
                            content=title,
                            url=url,
                            timestamp=timestamp,
                            sentiment=sentiment,
                            impact=base_impact,
                            category=category,
                            affected_coins=coins,
                            keywords_found=keywords,
                            confidence=confidence
                        )
                        
                        events.append(event)
                    
                except Exception as e:
                    logger.debug(f"[TWITTER] Error fetching @{username}: {e}")
                    continue
                
                await asyncio.sleep(0.5)  # Rate limiting –º–µ–∂–¥—É –∞–∫–∫–∞—É–Ω—Ç–∞–º–∏
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        events.sort(key=lambda x: x.timestamp, reverse=True)
        
        logger.info(f"[TWITTER] Fetched {len(events)} tweets from {len(accounts_to_fetch)} accounts")
        return events
    
    async def _fetch_twitter_via_rss_app(self, accounts: List[str]) -> List[NewsEvent]:
        """–ü–æ–ª—É—á–∏—Ç—å Twitter/–Ω–æ–≤–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ RSS.app Bundle YULA"""
        global _rss_app_feeds_cache
        events = []
        
        auth_header = f"Bearer {RSS_APP_API_KEY}:{RSS_APP_API_SECRET}"
        logger.info(f"[RSS.APP] Fetching from YULA bundle...")
        
        async with aiohttp.ClientSession() as session:
            # 1. –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ bundle YULA
            try:
                async with session.get(
                    f"{RSS_APP_API_URL}/bundles/{RSS_APP_BUNDLE_ID}",
                    headers={'Authorization': auth_header},
                    timeout=aiohttp.ClientTimeout(total=20)
                ) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        bundle_name = data.get('name', 'YULA')
                        items = data.get('items', [])
                        feeds_count = len(data.get('feeds', []))
                        
                        logger.info(f"[RSS.APP] ‚úÖ Bundle '{bundle_name}': {feeds_count} feeds, {len(items)} items")
                        
                        for item in items[:30]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 30 –ø–æ—Å—Ç–æ–≤
                            url = item.get('url', '')
                            is_twitter = 'twitter.com' in url or 'x.com' in url
                            source = 'üê¶ Twitter/X' if is_twitter else 'üì∞ News'
                            
                            event = self._parse_rss_app_feed_item(item, source, is_twitter)
                            if event:
                                events.append(event)
                        
                        if events:
                            logger.info(f"[RSS.APP] Got {len(events)} items from bundle")
                            events.sort(key=lambda x: x.timestamp, reverse=True)
                            return events
                    elif resp.status == 404:
                        logger.warning(f"[RSS.APP] Bundle not found")
                    else:
                        resp_text = await resp.text()
                        logger.warning(f"[RSS.APP] Bundle error: {resp.status} - {resp_text[:100]}")
            except Exception as e:
                logger.warning(f"[RSS.APP] Error fetching bundle: {e}")
            
            # 2. Fallback: –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∏–¥—ã –∏–∑ –∞–∫–∫–∞—É–Ω—Ç–∞
            try:
                async with session.get(
                    f"{RSS_APP_API_URL}/feeds?limit=30",
                    headers={'Authorization': auth_header},
                    timeout=aiohttp.ClientTimeout(total=15)
                ) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        existing_feeds = data.get('data', [])
                        logger.info(f"[RSS.APP] Fallback: {len(existing_feeds)} feeds")
                        
                        for feed in existing_feeds[:10]:
                            feed_id = feed.get('id')
                            feed_title = feed.get('title', 'Unknown')
                            source_url = feed.get('source_url', '')
                            is_twitter = 'twitter.com' in source_url or 'x.com' in source_url
                            
                            if feed_id:
                                try:
                                    async with session.get(
                                        f"{RSS_APP_API_URL}/feeds/{feed_id}",
                                        headers={'Authorization': auth_header},
                                        timeout=aiohttp.ClientTimeout(total=10)
                                    ) as feed_resp:
                                        if feed_resp.status == 200:
                                            feed_data = await feed_resp.json()
                                            items = feed_data.get('items', [])
                                            for item in items[:5]:
                                                source = 'üê¶ Twitter/X' if is_twitter else f'üì∞ {feed_title[:20]}'
                                                event = self._parse_rss_app_feed_item(item, source, is_twitter)
                                                if event:
                                                    events.append(event)
                                except:
                                    pass
                            await asyncio.sleep(0.1)
                        
                        if events:
                            logger.info(f"[RSS.APP] Got {len(events)} from individual feeds")
                            events.sort(key=lambda x: x.timestamp, reverse=True)
                            return events
            except Exception as e:
                logger.warning(f"[RSS.APP] Fallback error: {e}")
            
            # 3. Keyword search fallback
            crypto_keywords = ["bitcoin crypto", "ethereum defi", "SEC crypto"]
            # –ú–µ—Ç–æ–¥ 1: Keyword search (—Ç–æ—á–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏)
            for keyword in crypto_keywords[:3]:  # –õ–∏–º–∏—Ç–∏—Ä—É–µ–º —á—Ç–æ–±—ã –Ω–µ —Ç—Ä–∞—Ç–∏—Ç—å –æ–ø–µ—Ä–∞—Ü–∏–∏
                cache_key = f"keyword_{keyword.replace(' ', '_')}"
                feed_id = _rss_app_feeds_cache.get(cache_key)
                
                try:
                    if not feed_id:
                        logger.info(f"[RSS.APP] Creating feed for keyword: {keyword}")
                        async with session.post(
                            f"{RSS_APP_API_URL}/feeds",
                            headers={
                                'Authorization': auth_header,
                                'Content-Type': 'application/json'
                            },
                            json={
                                'keyword': keyword,
                                'region': 'US:en'
                            },
                            timeout=aiohttp.ClientTimeout(total=30)
                        ) as resp:
                            if resp.status == 200:
                                data = await resp.json()
                                feed_id = data.get('id')
                                if feed_id:
                                    _rss_app_feeds_cache[cache_key] = feed_id
                                    logger.info(f"[RSS.APP] ‚úÖ Created keyword feed: {feed_id}")
                                    
                                    items = data.get('items', [])
                                    logger.info(f"[RSS.APP] Keyword '{keyword}' has {len(items)} items")
                                    for item in items[:5]:
                                        event = self._parse_rss_app_keyword_item(item, keyword)
                                        if event:
                                            events.append(event)
                            elif resp.status == 429:
                                logger.warning("[RSS.APP] ‚ùå Rate limit!")
                                break
                            elif resp.status == 401:
                                logger.error("[RSS.APP] ‚ùå Unauthorized!")
                                break
                            else:
                                resp_text = await resp.text()
                                logger.warning(f"[RSS.APP] Keyword failed: {resp.status} - {resp_text[:100]}")
                    else:
                        # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∏–¥
                        async with session.get(
                            f"{RSS_APP_API_URL}/feeds/{feed_id}",
                            headers={'Authorization': auth_header},
                            timeout=aiohttp.ClientTimeout(total=15)
                        ) as resp:
                            if resp.status == 200:
                                data = await resp.json()
                                items = data.get('items', [])
                                for item in items[:5]:
                                    event = self._parse_rss_app_keyword_item(item, keyword)
                                    if event:
                                        events.append(event)
                            elif resp.status == 404:
                                del _rss_app_feeds_cache[cache_key]
                                
                except Exception as e:
                    logger.warning(f"[RSS.APP] Error for keyword '{keyword}': {e}")
                    continue
                
                await asyncio.sleep(0.3)
        
        logger.info(f"[RSS.APP] Total news fetched: {len(events)}")
        events.sort(key=lambda x: x.timestamp, reverse=True)
        return events
    
    def _parse_rss_app_feed_item(self, item: dict, source: str, is_twitter: bool = False) -> Optional[NewsEvent]:
        """–ü–∞—Ä—Å–∏–Ω–≥ item –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ RSS.app —Ñ–∏–¥–∞"""
        title = item.get('title', '') or item.get('description_text', '')
        
        if not title or len(title) < 10:
            return None
        
        # –û—á–∏—â–∞–µ–º title
        title = re.sub(r'<[^>]+>', '', title).strip()
        
        news_hash = self._get_news_hash(title, f"rssapp_{source[:15]}")
        if news_hash in self.seen_news:
            return None
        self.seen_news.append(news_hash)
        
        # –ê–Ω–∞–ª–∏–∑
        sentiment, confidence, keywords = self.analyze_sentiment(title)
        category = self.detect_category(title, 'twitter' if is_twitter else 'news')
        coins = self.extract_coins(title)
        
        # Impact –≤—ã—à–µ –¥–ª—è Twitter
        impact = NewsImpact.HIGH if is_twitter else NewsImpact.MEDIUM
        
        # Timestamp
        timestamp = datetime.now(timezone.utc)
        date_str = item.get('date_published')
        if date_str:
            try:
                timestamp = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
            except:
                pass
        
        return NewsEvent(
            id=news_hash,
            source=source,
            author=item.get('authors', [{}])[0].get('name', '') if item.get('authors') else '',
            title=title[:200],
            content=item.get('description_text', title)[:500],
            url=item.get('url', ''),
            timestamp=timestamp,
            sentiment=sentiment,
            impact=impact,
            category=category,
            affected_coins=coins,
            keywords_found=keywords,
            confidence=confidence
        )
    
    def _parse_rss_app_keyword_item(self, item: dict, keyword: str) -> Optional[NewsEvent]:
        """–ü–∞—Ä—Å–∏–Ω–≥ item –∏–∑ RSS.app keyword search –≤ NewsEvent"""
        title = item.get('title', '') or item.get('description_text', '')
        
        if not title or len(title) < 15:
            return None
        
        # –û—á–∏—â–∞–µ–º title
        title = re.sub(r'<[^>]+>', '', title).strip()
        
        news_hash = self._get_news_hash(title, f"rssapp_{keyword[:10]}")
        if news_hash in self.seen_news:
            return None
        self.seen_news.append(news_hash)
        
        # –ê–Ω–∞–ª–∏–∑
        sentiment, confidence, keywords = self.analyze_sentiment(title)
        category = self.detect_category(title, 'news')
        coins = self.extract_coins(title)
        
        # Timestamp
        timestamp = datetime.now(timezone.utc)
        date_str = item.get('date_published')
        if date_str:
            try:
                timestamp = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
            except:
                pass
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º source
        source_url = item.get('url', '')
        if 'cointelegraph' in source_url.lower():
            source = 'üì∞ CoinTelegraph'
        elif 'decrypt' in source_url.lower():
            source = 'üì∞ Decrypt'
        elif 'coindesk' in source_url.lower():
            source = 'üì∞ CoinDesk'
        elif 'twitter' in source_url.lower() or 'x.com' in source_url.lower():
            source = 'üê¶ Twitter/X'
        else:
            source = 'üì∞ Crypto News'
        
        return NewsEvent(
            id=news_hash,
            source=source,
            author=keyword,
            title=title[:200],
            content=item.get('description_text', title)[:500],
            url=item.get('url', ''),
            timestamp=timestamp,
            sentiment=sentiment,
            impact=NewsImpact.MEDIUM,
            category=category,
            affected_coins=coins,
            keywords_found=keywords,
            confidence=confidence
        )
    
    def _parse_rss_app_item(self, item: dict, username: str) -> Optional[NewsEvent]:
        """–ü–∞—Ä—Å–∏–Ω–≥ item –∏–∑ RSS.app –≤ NewsEvent"""
        title = item.get('title', '') or item.get('description_text', '')
        
        if not title or len(title) < 10:
            return None
        
        # –û—á–∏—â–∞–µ–º title
        title = re.sub(r'https?://\S+', '', title).strip()
        title = re.sub(r'@\w+', '', title).strip()
        
        if len(title) < 10:
            return None
        
        news_hash = self._get_news_hash(title, f"twitter_{username}")
        if news_hash in self.seen_news:
            return None
        self.seen_news.append(news_hash)
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–∫–∫–∞—É–Ω—Ç–µ
        account_info = TWITTER_ACCOUNTS.get(username, {
            'name': username,
            'type': 'unknown',
            'impact': 'MEDIUM',
            'keywords': []
        })
        
        # –ê–Ω–∞–ª–∏–∑
        sentiment, confidence, keywords = self.analyze_sentiment(title)
        category = self.detect_category(title, account_info.get('type', 'trader'))
        coins = self.extract_coins(title)
        
        # Impact
        try:
            impact = NewsImpact[account_info.get('impact', 'MEDIUM')]
        except:
            impact = NewsImpact.MEDIUM
        
        # Boost –¥–ª—è –≤–∞–∂–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤
        if account_info.get('type') in ['regulator', 'central_bank', 'government']:
            confidence = min(0.95, confidence + 0.2)
        
        # Timestamp
        timestamp = datetime.now(timezone.utc)
        date_str = item.get('date_published')
        if date_str:
            try:
                timestamp = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
            except:
                pass
        
        return NewsEvent(
            id=news_hash,
            source=f"üê¶ @{username}",
            author=account_info.get('name', username),
            title=title[:200],
            content=title,
            url=item.get('url', f"https://twitter.com/{username}"),
            timestamp=timestamp,
            sentiment=sentiment,
            impact=impact,
            category=category,
            affected_coins=coins,
            keywords_found=keywords,
            confidence=confidence
        )
    
    async def _fetch_twitter_via_rsshub(self, session, accounts: List[str]) -> List[NewsEvent]:
        """Fallback: –ø–æ–ª—É—á–∏—Ç—å —Ç–≤–∏—Ç—ã —á–µ—Ä–µ–∑ RSSHub"""
        events = []
        global _working_rsshub_instance, _rsshub_last_check
        
        working_rsshub = _working_rsshub_instance
        for instance in RSSHUB_INSTANCES:
            try:
                async with session.get(
                    f"{instance}/twitter/user/elonmusk",
                    timeout=aiohttp.ClientTimeout(total=8),
                    headers={'User-Agent': 'Mozilla/5.0'}
                ) as resp:
                    if resp.status == 200:
                        working_rsshub = instance
                        break
            except:
                continue
        
        if not working_rsshub:
            return events
        
        for username in accounts:
            try:
                url = f"{working_rsshub}/twitter/user/{username}"
                async with session.get(
                    url,
                    timeout=aiohttp.ClientTimeout(total=10),
                    headers={'User-Agent': 'Mozilla/5.0', 'Accept': 'application/xml'}
                ) as resp:
                    if resp.status != 200:
                        continue
                    content = await resp.text()
                
                items = re.findall(r'<item>(.*?)</item>', content, re.DOTALL)
                account_info = TWITTER_ACCOUNTS.get(username, {'name': username, 'type': 'unknown', 'impact': 'MEDIUM', 'keywords': []})
                
                for item in items[:3]:
                    title_match = re.search(r'<title[^>]*>(.*?)</title>', item, re.DOTALL)
                    if not title_match:
                        continue
                    
                    title = re.sub(r'<!\[CDATA\[(.*?)\]\]>', r'\1', title_match.group(1))
                    title = re.sub(r'<[^>]+>', '', title).strip()
                    
                    if not title or len(title) < 15:
                        continue
                    
                    news_hash = self._get_news_hash(title, f"twitter_{username}")
                    if news_hash in self.seen_news:
                        continue
                    self.seen_news.append(news_hash)
                    
                    sentiment, confidence, keywords = self.analyze_sentiment(title)
                    category = self.detect_category(title, account_info.get('type', 'trader'))
                    coins = self.extract_coins(title)
                    
                    try:
                        impact = NewsImpact[account_info.get('impact', 'MEDIUM')]
                    except:
                        impact = NewsImpact.MEDIUM
                    
                    event = NewsEvent(
                        id=news_hash,
                        source=f"üê¶ @{username}",
                        author=account_info.get('name', username),
                        title=title[:200],
                        content=title,
                        url=f"https://twitter.com/{username}",
                        timestamp=datetime.now(timezone.utc),
                        sentiment=sentiment,
                        impact=impact,
                        category=category,
                        affected_coins=coins,
                        keywords_found=keywords,
                        confidence=confidence
                    )
                    events.append(event)
                    
            except Exception as e:
                logger.debug(f"[RSSHUB] Error fetching @{username}: {e}")
                continue
            
            await asyncio.sleep(0.3)
        
        return events
    
    async def fetch_coingecko_trending(self) -> List[NewsEvent]:
        """
        –ü–æ–ª—É—á–∏—Ç—å trending –º–æ–Ω–µ—Ç—ã —Å CoinGecko - —Ö–æ—Ä–æ—à–∏–π –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä —Ö–∞–π–ø–∞
        """
        events = []
        
        try:
            async with aiohttp.ClientSession() as session:
                # Trending coins
                async with session.get(
                    'https://api.coingecko.com/api/v3/search/trending',
                    timeout=aiohttp.ClientTimeout(total=10),
                    headers={'Accept': 'application/json'}
                ) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        
                        for idx, coin_data in enumerate(data.get('coins', [])[:7]):
                            coin = coin_data.get('item', {})
                            name = coin.get('name', '')
                            symbol = coin.get('symbol', '').upper()
                            
                            if not symbol:
                                continue
                            
                            # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤–æ—Å—Ç—å –æ trending –º–æ–Ω–µ—Ç–µ
                            title = f"üî• {symbol} trending #{idx+1} on CoinGecko"
                            
                            news_hash = self._get_news_hash(f"trending_{symbol}", "coingecko")
                            if news_hash in self.seen_news:
                                continue
                            self.seen_news.append(news_hash)
                            
                            # Trending = –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ bullish (—Ö–∞–π–ø)
                            event = NewsEvent(
                                id=news_hash,
                                source='CoinGecko Trending',
                                author='CoinGecko',
                                title=title,
                                content=f"{name} ({symbol}) is trending",
                                url=f"https://www.coingecko.com/en/coins/{coin.get('id', '')}",
                                timestamp=datetime.now(timezone.utc),
                                sentiment=NewsSentiment.BULLISH,
                                impact=NewsImpact.MEDIUM,
                                category=NewsCategory.OTHER,
                                affected_coins=[symbol],
                                keywords_found=['trending', 'hype'],
                                confidence=0.5 + (0.05 * (7 - idx))  # Higher rank = higher confidence
                            )
                            events.append(event)
                
                logger.info(f"[NEWS] CoinGecko trending: {len(events)} coins")
                
        except Exception as e:
            logger.debug(f"[NEWS] CoinGecko error: {e}")
        
        return events
    
    # ==================== COINGLASS INTEGRATION ====================
    
    async def fetch_coinglass_funding(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å funding rates —Å Coinglass
        –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è = —Å–∏–≥–Ω–∞–ª –Ω–∞ —Ä–∞–∑–≤–æ—Ä–æ—Ç
        """
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    'https://open-api.coinglass.com/public/v2/funding',
                    timeout=aiohttp.ClientTimeout(total=10),
                    headers={'Accept': 'application/json'}
                ) as resp:
                    if resp.status != 200:
                        return {}
                    data = await resp.json()
                    
                    result = {'extreme_long': [], 'extreme_short': [], 'neutral': []}
                    
                    for item in data.get('data', []):
                        symbol = item.get('symbol', '')
                        rate = float(item.get('uMarginList', [{}])[0].get('rate', 0) or 0)
                        
                        if rate > COINGLASS_THRESHOLDS['extreme_funding_long']:
                            result['extreme_long'].append({
                                'symbol': symbol,
                                'rate': rate,
                                'signal': 'SHORT'  # –ú–Ω–æ–≥–æ –ª–æ–Ω–≥–æ–≤ = –≤–æ–∑–º–æ–∂–µ–Ω —à–æ—Ä—Ç
                            })
                            logger.info(f"[COINGLASS] üî¥ {symbol} EXTREME LONG funding: {rate:.4%}")
                        elif rate < COINGLASS_THRESHOLDS['extreme_funding_short']:
                            result['extreme_short'].append({
                                'symbol': symbol,
                                'rate': rate,
                                'signal': 'LONG'  # –ú–Ω–æ–≥–æ —à–æ—Ä—Ç–æ–≤ = –≤–æ–∑–º–æ–∂–µ–Ω —à–æ—Ä—Ç-—Å–∫–≤–∏–∑
                            })
                            logger.info(f"[COINGLASS] üü¢ {symbol} EXTREME SHORT funding: {rate:.4%}")
                        else:
                            result['neutral'].append({'symbol': symbol, 'rate': rate})
                    
                    return result
                    
        except Exception as e:
            logger.debug(f"[COINGLASS] Funding error: {e}")
            return {}
    
    async def fetch_coinglass_liquidations(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ –ª–∏–∫–≤–∏–¥–∞—Ü–∏—è—Ö —Å Coinglass
        –ë–æ–ª—å—à–∏–µ –ª–∏–∫–≤–∏–¥–∞—Ü–∏–∏ = –≤–æ–∑–º–æ–∂–Ω—ã–π —Ä–∞–∑–≤–æ—Ä–æ—Ç
        """
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    'https://open-api.coinglass.com/public/v2/liquidation_chart?symbol=BTC',
                    timeout=aiohttp.ClientTimeout(total=10),
                    headers={'Accept': 'application/json'}
                ) as resp:
                    if resp.status != 200:
                        return {}
                    data = await resp.json()
                    
                    result = {
                        'total_24h': 0,
                        'long_liquidations': 0,
                        'short_liquidations': 0,
                        'signal': None
                    }
                    
                    chart_data = data.get('data', [])
                    if chart_data:
                        # –°—É–º–º–∏—Ä—É–µ–º –ª–∏–∫–≤–∏–¥–∞—Ü–∏–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
                        for item in chart_data[-24:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
                            result['long_liquidations'] += float(item.get('longLiquidationUsd', 0) or 0)
                            result['short_liquidations'] += float(item.get('shortLiquidationUsd', 0) or 0)
                        
                        result['total_24h'] = result['long_liquidations'] + result['short_liquidations']
                        
                        # –ê–Ω–∞–ª–∏–∑
                        if result['total_24h'] > COINGLASS_THRESHOLDS['liquidation_spike']:
                            if result['long_liquidations'] > result['short_liquidations'] * 1.5:
                                result['signal'] = 'LONG'  # –õ–æ–Ω–≥–∏ –ª–∏–∫–≤–∏–¥–∏—Ä–æ–≤–∞–Ω—ã = –≤–æ–∑–º–æ–∂–µ–Ω –æ—Ç—Å–∫–æ–∫
                                logger.info(f"[COINGLASS] üí• LONG LIQUIDATIONS ${result['long_liquidations']/1e6:.1f}M - possible bounce")
                            elif result['short_liquidations'] > result['long_liquidations'] * 1.5:
                                result['signal'] = 'SHORT'  # –®–æ—Ä—Ç—ã –ª–∏–∫–≤–∏–¥–∏—Ä–æ–≤–∞–Ω—ã = –≤–æ–∑–º–æ–∂–µ–Ω –æ—Ç–∫–∞—Ç
                                logger.info(f"[COINGLASS] üí• SHORT LIQUIDATIONS ${result['short_liquidations']/1e6:.1f}M - possible pullback")
                    
                    return result
                    
        except Exception as e:
            logger.debug(f"[COINGLASS] Liquidations error: {e}")
            return {}
    
    async def fetch_coinglass_long_short_ratio(self, symbol: str = 'BTC') -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ Long/Short —Å Coinglass
        –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è = –∫–æ–Ω—Ç—Ä-—Å–∏–≥–Ω–∞–ª
        """
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    f'https://open-api.coinglass.com/public/v2/long_short_ratio?symbol={symbol}&interval=h1',
                    timeout=aiohttp.ClientTimeout(total=10),
                    headers={'Accept': 'application/json'}
                ) as resp:
                    if resp.status != 200:
                        return {}
                    data = await resp.json()
                    
                    result = {
                        'symbol': symbol,
                        'long_ratio': 50,
                        'short_ratio': 50,
                        'signal': None
                    }
                    
                    ls_data = data.get('data', [])
                    if ls_data:
                        latest = ls_data[-1]
                        result['long_ratio'] = float(latest.get('longRatio', 50) or 50)
                        result['short_ratio'] = 100 - result['long_ratio']
                        
                        # –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è = –∫–æ–Ω—Ç—Ä-—Å–∏–≥–Ω–∞–ª
                        if result['long_ratio'] > COINGLASS_THRESHOLDS['long_short_extreme_long']:
                            result['signal'] = 'SHORT'  # –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ª–æ–Ω–≥–æ–≤
                            logger.info(f"[COINGLASS] üìä {symbol} EXTREME LONG RATIO: {result['long_ratio']:.1f}% - contrarian SHORT")
                        elif result['long_ratio'] < COINGLASS_THRESHOLDS['long_short_extreme_short']:
                            result['signal'] = 'LONG'  # –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —à–æ—Ä—Ç–æ–≤ = —à–æ—Ä—Ç-—Å–∫–≤–∏–∑
                            logger.info(f"[COINGLASS] üìä {symbol} EXTREME SHORT RATIO: {result['short_ratio']:.1f}% - possible SHORT SQUEEZE")
                    
                    return result
                    
        except Exception as e:
            logger.debug(f"[COINGLASS] Long/Short ratio error: {e}")
            return {}
    
    async def fetch_dexscreener_trending(self) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å trending —Ç–æ–∫–µ–Ω—ã —Å DexScreener
        –•–æ—Ä–æ—à–∏–π –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä —Ö–∞–π–ø–∞ –Ω–∞ DEX
        """
        try:
            async with aiohttp.ClientSession() as session:
                # Top gainers
                async with session.get(
                    'https://api.dexscreener.com/token-boosts/top/v1',
                    timeout=aiohttp.ClientTimeout(total=10),
                    headers={'Accept': 'application/json'}
                ) as resp:
                    if resp.status != 200:
                        return []
                    data = await resp.json()
                    
                    trending = []
                    for item in data[:20]:  # Top 20
                        symbol = item.get('tokenAddress', '')[:8]
                        name = item.get('description', '')
                        chain = item.get('chainId', '')
                        
                        trending.append({
                            'symbol': symbol,
                            'name': name,
                            'chain': chain,
                            'url': item.get('url', ''),
                            'signal': 'WATCH'  # –û—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å —Ö–∞–π–ø
                        })
                    
                    if trending:
                        logger.info(f"[DEXSCREENER] Found {len(trending)} trending tokens")
                    
                    return trending
                    
        except Exception as e:
            logger.debug(f"[DEXSCREENER] Error: {e}")
            return []
    
    async def get_coinglass_signals(self) -> Dict[str, Any]:
        """
        –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å Coinglass
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ—Ä–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ:
        - Funding rates
        - Liquidations
        - Long/Short ratio
        """
        signals = {
            'funding': {},
            'liquidations': {},
            'long_short': {},
            'overall_signal': None,
            'confidence': 0.5
        }
        
        try:
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –ø–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
            funding, liquidations, ls_btc, ls_eth = await asyncio.gather(
                self.fetch_coinglass_funding(),
                self.fetch_coinglass_liquidations(),
                self.fetch_coinglass_long_short_ratio('BTC'),
                self.fetch_coinglass_long_short_ratio('ETH'),
                return_exceptions=True
            )
            
            if not isinstance(funding, Exception):
                signals['funding'] = funding
            if not isinstance(liquidations, Exception):
                signals['liquidations'] = liquidations
            if not isinstance(ls_btc, Exception):
                signals['long_short']['BTC'] = ls_btc
            if not isinstance(ls_eth, Exception):
                signals['long_short']['ETH'] = ls_eth
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã
            long_votes = 0
            short_votes = 0
            
            # Funding signals
            if signals['funding'].get('extreme_short'):
                long_votes += len(signals['funding']['extreme_short'])
            if signals['funding'].get('extreme_long'):
                short_votes += len(signals['funding']['extreme_long'])
            
            # Liquidation signal
            if signals['liquidations'].get('signal') == 'LONG':
                long_votes += 2
            elif signals['liquidations'].get('signal') == 'SHORT':
                short_votes += 2
            
            # Long/Short ratio
            for ls_data in signals['long_short'].values():
                if isinstance(ls_data, dict):
                    if ls_data.get('signal') == 'LONG':
                        long_votes += 1
                    elif ls_data.get('signal') == 'SHORT':
                        short_votes += 1
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–π —Å–∏–≥–Ω–∞–ª
            total_votes = long_votes + short_votes
            if total_votes > 0:
                if long_votes > short_votes:
                    signals['overall_signal'] = 'LONG'
                    signals['confidence'] = 0.5 + (long_votes / total_votes) * 0.3
                elif short_votes > long_votes:
                    signals['overall_signal'] = 'SHORT'
                    signals['confidence'] = 0.5 + (short_votes / total_votes) * 0.3
            
            if signals['overall_signal']:
                logger.info(f"[COINGLASS] Overall signal: {signals['overall_signal']} (confidence: {signals['confidence']:.0%})")
            
        except Exception as e:
            logger.error(f"[COINGLASS] Aggregation error: {e}")
        
        return signals
    
    # ==================== END COINGLASS ====================
    
    async def fetch_binance_announcements(self) -> List[NewsEvent]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤–∞–∂–Ω—ã–µ –∞–Ω–æ–Ω—Å—ã —Å Binance (–ª–∏—Å—Ç–∏–Ω–≥–∏, –¥–µ–ª–∏—Å—Ç–∏–Ω–≥–∏)
        """
        events = []
        
        try:
            async with aiohttp.ClientSession() as session:
                # Binance announcements API
                async with session.get(
                    'https://www.binance.com/bapi/composite/v1/public/cms/article/list/query',
                    params={
                        'type': 1,
                        'pageNo': 1,
                        'pageSize': 20
                    },
                    timeout=aiohttp.ClientTimeout(total=10),
                    headers={
                        'User-Agent': 'Mozilla/5.0',
                        'Accept': 'application/json'
                    }
                ) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        
                        articles = data.get('data', {}).get('catalogs', [])
                        
                        for catalog in articles:
                            for article in catalog.get('articles', [])[:10]:
                                title = article.get('title', '')
                                
                                if not title:
                                    continue
                                
                                news_hash = self._get_news_hash(title, "binance")
                                if news_hash in self.seen_news:
                                    continue
                                self.seen_news.append(news_hash)
                                
                                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∞–Ω–æ–Ω—Å–∞
                                title_lower = title.lower()
                                
                                if 'list' in title_lower and 'delist' not in title_lower:
                                    sentiment = NewsSentiment.VERY_BULLISH
                                    impact = NewsImpact.HIGH
                                    category = NewsCategory.LISTING
                                elif 'delist' in title_lower or 'remove' in title_lower:
                                    sentiment = NewsSentiment.VERY_BEARISH
                                    impact = NewsImpact.HIGH
                                    category = NewsCategory.LISTING
                                elif 'maintenance' in title_lower or 'suspend' in title_lower:
                                    sentiment = NewsSentiment.BEARISH
                                    impact = NewsImpact.MEDIUM
                                    category = NewsCategory.OTHER
                                else:
                                    sentiment = NewsSentiment.NEUTRAL
                                    impact = NewsImpact.LOW
                                    category = NewsCategory.OTHER
                                
                                coins = self.extract_coins(title)
                                
                                event = NewsEvent(
                                    id=news_hash,
                                    source='Binance',
                                    author='Binance',
                                    title=title[:200],
                                    content=title,
                                    url=f"https://www.binance.com/en/support/announcement",
                                    timestamp=datetime.now(timezone.utc),
                                    sentiment=sentiment,
                                    impact=impact,
                                    category=category,
                                    affected_coins=coins,
                                    keywords_found=[],
                                    confidence=0.7 if impact.value >= NewsImpact.HIGH.value else 0.5
                                )
                                events.append(event)
                
                logger.info(f"[NEWS] Binance announcements: {len(events)}")
                
        except Exception as e:
            logger.debug(f"[NEWS] Binance announcements error: {e}")
        
        return events
    
    # ==================== MACRO EVENTS ====================
    
    def get_upcoming_macro_events(self, hours_ahead: int = 24) -> List[MacroEvent]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å—Ç–æ—è—â–∏–µ –º–∞–∫—Ä–æ-—Å–æ–±—ã—Ç–∏—è"""
        events = []
        now = datetime.now(timezone.utc)
        
        # –£–ø—Ä–æ—â—ë–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞: –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—É—â–∏–π –¥–µ–Ω—å
        weekday = now.weekday()
        hour = now.hour
        
        for event_name, event_info in MACRO_EVENTS.items():
            if weekday in event_info['typical_days']:
                for event_hour in event_info['typical_hours']:
                    if hour <= event_hour < hour + hours_ahead:
                        scheduled = now.replace(hour=event_hour, minute=0, second=0)
                        events.append(MacroEvent(
                            name=event_name,
                            description=event_info['description'],
                            scheduled_time=scheduled,
                            impact=NewsImpact[event_info['impact']]
                        ))
        
        return events
    
    def is_macro_event_window(self) -> Tuple[bool, Optional[str]]:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω–∞—Ö–æ–¥–∏–º—Å—è –ª–∏ –º—ã –≤ –æ–∫–Ω–µ –º–∞–∫—Ä–æ-—Å–æ–±—ã—Ç–∏—è"""
        now = datetime.now(timezone.utc)
        weekday = now.weekday()
        hour = now.hour
        
        for event_name, event_info in MACRO_EVENTS.items():
            if weekday in event_info['typical_days']:
                for event_hour in event_info['typical_hours']:
                    # –ó–∞ 30 –º–∏–Ω –¥–æ –∏ 30 –º–∏–Ω –ø–æ—Å–ª–µ
                    if event_hour - 1 <= hour <= event_hour + 1:
                        return True, event_name
        
        return False, None
    
    # ==================== SIGNAL GENERATION ====================
    
    def generate_trading_signal(self, event: NewsEvent) -> Optional[TradingSignal]:
        """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–æ—Ä–≥–æ–≤—ã–π —Å–∏–≥–Ω–∞–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤–æ—Å—Ç–∏"""
        
        # –§–∏–ª—å—Ç—Ä –ø–æ –∏–º–ø–∞–∫—Ç—É
        if event.impact.value < NewsImpact.MEDIUM.value:
            return None
        
        # –§–∏–ª—å—Ç—Ä –ø–æ confidence
        if event.confidence < 0.5:
            return None
        
        reasoning = []
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
        direction = None
        confidence = event.confidence
        
        if event.sentiment in [NewsSentiment.VERY_BULLISH, NewsSentiment.BULLISH]:
            direction = 'LONG'
            reasoning.append(f"üìà –ü–æ–∑–∏—Ç–∏–≤–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å: {event.sentiment.name}")
        elif event.sentiment in [NewsSentiment.VERY_BEARISH, NewsSentiment.BEARISH]:
            direction = 'SHORT'
            reasoning.append(f"üìâ –ù–µ–≥–∞—Ç–∏–≤–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å: {event.sentiment.name}")
        else:
            return None  # –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –Ω–µ —Ç–æ—Ä–≥—É–µ–º
        
        # –ú–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        if event.impact == NewsImpact.CRITICAL:
            confidence = min(0.95, confidence + 0.2)
            reasoning.append(f"‚ö° –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –≤–ª–∏—è–Ω–∏–µ")
        elif event.impact == NewsImpact.HIGH:
            confidence = min(0.9, confidence + 0.1)
            reasoning.append(f"üî• –í—ã—Å–æ–∫–æ–µ –≤–ª–∏—è–Ω–∏–µ")
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏—è
        reasoning.append(f"üìÅ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {event.category.value}")
        
        # –ò—Å—Ç–æ—á–Ω–∏–∫
        reasoning.append(f"üì∞ –ò—Å—Ç–æ—á–Ω–∏–∫: {event.source}")
        
        # –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ —Å–∏–≥–Ω–∞–ª–∞
        if event.category in [NewsCategory.MACRO, NewsCategory.REGULATION]:
            expires_delta = timedelta(hours=4)
            time_sensitive = True
        elif event.category == NewsCategory.HACK_EXPLOIT:
            expires_delta = timedelta(hours=1)
            time_sensitive = True
        else:
            expires_delta = timedelta(hours=2)
            time_sensitive = False
        
        return TradingSignal(
            direction=direction,
            confidence=confidence,
            source=event.source,
            reasoning=reasoning,
            affected_coins=event.affected_coins,
            time_sensitive=time_sensitive,
            expires_at=datetime.now(timezone.utc) + expires_delta,
            impact=event.impact
        )
    
    async def get_aggregated_signals(self) -> List[TradingSignal]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–æ—Ä–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        """
        all_events = []
        signals = []
        
        # –°–æ–±–∏—Ä–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        tasks = [
            self.fetch_cryptopanic_news(),        # CryptoPanic API
            self.fetch_twitter_sentiment(),        # RSS –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ –ª–µ–Ω—Ç—ã (CoinTelegraph, Decrypt, etc.)
            self.fetch_fear_greed_index(),         # Fear & Greed Index
            self.fetch_coingecko_trending(),       # Trending –Ω–∞ CoinGecko
            self.fetch_binance_announcements(),    # –ê–Ω–æ–Ω—Å—ã Binance
            self.get_coinglass_signals(),          # Coinglass (funding, liquidations, L/S ratio)
            self.fetch_dexscreener_trending(),     # DexScreener trending tokens
            self.fetch_twitter_posts()             # Twitter/X –ø–æ—Å—Ç—ã –æ—Ç –∫–ª—é—á–µ–≤—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # CryptoPanic
        if isinstance(results[0], list):
            all_events.extend(results[0])
        
        # RSS News (CoinTelegraph, Decrypt, etc.)
        if isinstance(results[1], list):
            all_events.extend(results[1])
        
        # CoinGecko Trending
        if isinstance(results[3], list):
            all_events.extend(results[3])
        
        # Twitter Posts (index 7)
        if isinstance(results[7], list):
            all_events.extend(results[7])
            logger.info(f"[TWITTER] Added {len(results[7])} tweets to news feed")
        
        # Binance Announcements
        if isinstance(results[4], list):
            all_events.extend(results[4])
        
        # === COINGLASS SIGNALS ===
        if isinstance(results[5], dict):
            cg = results[5]
            overall = cg.get('overall_signal')
            if overall:
                conf = cg.get('confidence', 0.5)
                reasons = []
                
                # Funding
                if cg.get('funding', {}).get('extreme_long'):
                    reasons.append(f"üî¥ {len(cg['funding']['extreme_long'])} –º–æ–Ω–µ—Ç —Å —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–º funding")
                if cg.get('funding', {}).get('extreme_short'):
                    reasons.append(f"üü¢ {len(cg['funding']['extreme_short'])} –º–æ–Ω–µ—Ç —Å –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–º funding")
                
                # Liquidations
                liq = cg.get('liquidations', {})
                if liq.get('total_24h', 0) > 50_000_000:
                    reasons.append(f"üí• –õ–∏–∫–≤–∏–¥–∞—Ü–∏–π: ${liq['total_24h']/1e6:.1f}M –∑–∞ 24—á")
                
                # L/S Ratio
                for symbol, ls in cg.get('long_short', {}).items():
                    if isinstance(ls, dict) and ls.get('signal'):
                        reasons.append(f"üìä {symbol} L/S Ratio: {ls.get('long_ratio', 50):.1f}%")
                
                if reasons:
                    signals.append(TradingSignal(
                        direction=overall,
                        confidence=conf,
                        source='Coinglass Analytics',
                        reasoning=reasons,
                        affected_coins=['BTC', 'ETH'],
                        time_sensitive=True,
                        expires_at=datetime.now(timezone.utc) + timedelta(hours=4),
                        impact=NewsImpact.HIGH
                    ))
                    logger.info(f"[COINGLASS] Signal: {overall} ({conf:.0%}) - {reasons[0]}")
        
        # === DEXSCREENER TRENDING ===
        if isinstance(results[6], list) and results[6]:
            trending_coins = [t['symbol'][:10] for t in results[6][:5]]
            signals.append(TradingSignal(
                direction='WATCH',
                confidence=0.4,
                source='DexScreener Trending',
                reasoning=[f"üî• DEX Trending: {', '.join(trending_coins)}"],
                affected_coins=trending_coins,
                time_sensitive=True,
                expires_at=datetime.now(timezone.utc) + timedelta(hours=2),
                impact=NewsImpact.MEDIUM
            ))
            logger.info(f"[DEXSCREENER] Trending: {trending_coins}")
        
        # Fear & Greed –≤–ª–∏—è–µ—Ç –Ω–∞ –æ–±—â–∏–π —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç
        if isinstance(results[2], dict):
            fg = results[2]
            fg_value = fg.get('value', 50)
            
            if fg_value <= 25:  # Extreme Fear
                # –ö–æ–Ω—Ç—Ä-—Å–∏–≥–Ω–∞–ª: –ø–æ–∫—É–ø–∞–µ–º –Ω–∞ —Å—Ç—Ä–∞—Ö–µ
                signals.append(TradingSignal(
                    direction='LONG',
                    confidence=0.6,
                    source='Fear & Greed Index',
                    reasoning=[
                        f"üò± Extreme Fear: {fg_value}",
                        "–ö–æ–Ω—Ç—Ä-—Ç—Ä–µ–Ω–¥: –ø–æ–∫—É–ø–∫–∞ –Ω–∞ —Å—Ç—Ä–∞—Ö–µ",
                        f"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: {fg.get('classification')}"
                    ],
                    affected_coins=['BTC', 'ETH'],
                    time_sensitive=False,
                    expires_at=datetime.now(timezone.utc) + timedelta(hours=6),
                    impact=NewsImpact.MEDIUM
                ))
            elif fg_value >= 75:  # Extreme Greed
                # –ö–æ–Ω—Ç—Ä-—Å–∏–≥–Ω–∞–ª: –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç—å –Ω–∞ –∂–∞–¥–Ω–æ—Å—Ç–∏
                signals.append(TradingSignal(
                    direction='SHORT',
                    confidence=0.5,
                    source='Fear & Greed Index',
                    reasoning=[
                        f"ü§ë Extreme Greed: {fg_value}",
                        "–ö–æ–Ω—Ç—Ä-—Ç—Ä–µ–Ω–¥: –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç—å –Ω–∞ –∂–∞–¥–Ω–æ—Å—Ç–∏",
                        f"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: {fg.get('classification')}"
                    ],
                    affected_coins=['BTC', 'ETH'],
                    time_sensitive=False,
                    expires_at=datetime.now(timezone.utc) + timedelta(hours=6),
                    impact=NewsImpact.MEDIUM
                ))
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã –∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π
        for event in all_events:
            signal = self.generate_trading_signal(event)
            if signal:
                signals.append(signal)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ confidence –∏ impact
        signals.sort(key=lambda s: (s.impact.value, s.confidence), reverse=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–±—ã—Ç–∏—è
        for event in all_events:
            self.recent_events.append(event)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º market sentiment
        self._update_market_sentiment(all_events)
        
        logger.info(f"[NEWS] Generated {len(signals)} trading signals")
        return signals
    
    def _update_market_sentiment(self, events: List[NewsEvent]):
        """–û–±–Ω–æ–≤–∏—Ç—å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä—ã–Ω–æ—á–Ω—ã–π —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç"""
        if not events:
            return
        
        total_score = 0
        total_weight = 0
        
        for event in events:
            weight = event.impact.value * event.confidence
            score = event.sentiment.value * 25  # -50 to +50
            total_score += score * weight
            total_weight += weight
        
        if total_weight > 0:
            final_score = total_score / total_weight
            self.market_sentiment['score'] = max(-100, min(100, final_score))
            
            if final_score > 20:
                self.market_sentiment['trend'] = 'BULLISH'
            elif final_score < -20:
                self.market_sentiment['trend'] = 'BEARISH'
            else:
                self.market_sentiment['trend'] = 'NEUTRAL'
            
            self.market_sentiment['last_update'] = datetime.now(timezone.utc)
    
    def get_market_sentiment(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π —Ä—ã–Ω–æ—á–Ω—ã–π —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç"""
        return self.market_sentiment.copy()
    
    # ==================== MANIPULATION DETECTION ====================
    
    async def detect_manipulation_news(self) -> List[Dict]:
        """
        –î–µ—Ç–µ–∫—Ü–∏—è –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞:
        1. –í–Ω–µ–∑–∞–ø–Ω—ã–π –ø–æ—Ç–æ–∫ FUD
        2. –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ pump-–ø–æ—Å—Ç—ã
        3. –§–µ–π–∫–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
        """
        alerts = []
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è
        recent = list(self.recent_events)[-50:]
        
        if len(recent) < 5:
            return alerts
        
        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ FUD-–∞—Ç–∞–∫—É (–º–Ω–æ–≥–æ –Ω–µ–≥–∞—Ç–∏–≤–∞ –∑–∞ –∫–æ—Ä–æ—Ç–∫–æ–µ –≤—Ä–µ–º—è)
        last_hour = datetime.now(timezone.utc) - timedelta(hours=1)
        recent_negative = [e for e in recent 
                          if e.timestamp > last_hour 
                          and e.sentiment.value < 0]
        
        if len(recent_negative) >= 5:
            alerts.append({
                'type': 'FUD_ATTACK',
                'severity': 'HIGH',
                'description': f'–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(recent_negative)} –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ —á–∞—Å',
                'recommendation': '–í–æ–∑–º–æ–∂–Ω–∞—è –º–∞–Ω–∏–ø—É–ª—è—Ü–∏—è. –ù–µ –ø–∞–Ω–∏–∫–æ–≤–∞—Ç—å, –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏.'
            })
        
        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ pump-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—é
        recent_positive = [e for e in recent 
                          if e.timestamp > last_hour 
                          and e.sentiment.value > 0
                          and e.category == NewsCategory.TRADER_CALL]
        
        if len(recent_positive) >= 3:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≥–æ–≤–æ—Ä—è—Ç –ª–∏ –æ –æ–¥–Ω–æ–π –º–æ–Ω–µ—Ç–µ
            coin_counts = {}
            for e in recent_positive:
                for coin in e.affected_coins:
                    coin_counts[coin] = coin_counts.get(coin, 0) + 1
            
            for coin, count in coin_counts.items():
                if count >= 3:
                    alerts.append({
                        'type': 'COORDINATED_PUMP',
                        'severity': 'MEDIUM',
                        'description': f'{count} —Ç—Ä–µ–π–¥–µ—Ä–æ–≤ –≥–æ–≤–æ—Ä—è—Ç –æ {coin}',
                        'recommendation': f'–í–æ–∑–º–æ–∂–Ω—ã–π pump {coin}. –û—Å—Ç–æ—Ä–æ–∂–Ω–æ —Å –≤—Ö–æ–¥–æ–º.'
                    })
        
        return alerts
    
    # ==================== API FUNCTIONS ====================
    
    async def get_news_for_coin(self, coin: str) -> List[NewsEvent]:
        """–ü–æ–ª—É—á–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–Ω–µ—Ç—ã"""
        all_events = list(self.recent_events)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –º–æ–Ω–µ—Ç–µ
        coin_upper = coin.upper().replace('USDT', '').replace('/USDT', '')
        
        relevant = [e for e in all_events if coin_upper in e.affected_coins]
        
        return sorted(relevant, key=lambda x: x.timestamp, reverse=True)[:10]
    
    async def should_avoid_trading(self) -> Tuple[bool, Optional[str]]:
        """
        –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —Å—Ç–æ–∏—Ç –ª–∏ –∏–∑–±–µ–≥–∞—Ç—å —Ç–æ—Ä–≥–æ–≤–ª–∏ —Å–µ–π—á–∞—Å
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (should_avoid, reason)
        """
        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∞–∫—Ä–æ-—Å–æ–±—ã—Ç–∏—è
        is_macro, macro_event = self.is_macro_event_window()
        if is_macro:
            return True, f"–û–∫–Ω–æ –º–∞–∫—Ä–æ-—Å–æ–±—ã—Ç–∏—è: {macro_event}"
        
        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏
        manipulations = await self.detect_manipulation_news()
        if any(m['severity'] == 'HIGH' for m in manipulations):
            return True, "–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –≤–æ–∑–º–æ–∂–Ω–∞—è –º–∞–Ω–∏–ø—É–ª—è—Ü–∏—è"
        
        # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º extreme sentiment
        sentiment = self.get_market_sentiment()
        if abs(sentiment['score']) > 80:
            return False, f"‚ö†Ô∏è –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–π —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç: {sentiment['score']}"
        
        return False, None


# ==================== –ì–õ–û–ë–ê–õ–¨–ù–´–ô –≠–ö–ó–ï–ú–ü–õ–Ø–† ====================

news_analyzer = NewsAnalyzer()


# ==================== API –§–£–ù–ö–¶–ò–ò ====================

async def get_news_signals() -> List[TradingSignal]:
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–æ—Ä–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤–æ—Å—Ç–µ–π"""
    return await news_analyzer.get_aggregated_signals()


async def get_market_sentiment() -> Dict:
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π —Ä—ã–Ω–æ—á–Ω—ã–π —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç"""
    # –û–±–Ω–æ–≤–ª—è–µ–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if not news_analyzer.market_sentiment.get('last_update'):
        await news_analyzer.get_aggregated_signals()
    return news_analyzer.get_market_sentiment()


async def get_news_for_coin(coin: str) -> List[NewsEvent]:
    """–ü–æ–ª—É—á–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –º–æ–Ω–µ—Ç—ã"""
    return await news_analyzer.get_news_for_coin(coin)


async def should_trade_now() -> Tuple[bool, Optional[str]]:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –º–æ–∂–Ω–æ –ª–∏ —Ç–æ—Ä–≥–æ–≤–∞—Ç—å —Å–µ–π—á–∞—Å"""
    should_avoid, reason = await news_analyzer.should_avoid_trading()
    return not should_avoid, reason


async def get_upcoming_events() -> List[MacroEvent]:
    """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å—Ç–æ—è—â–∏–µ –º–∞–∫—Ä–æ-—Å–æ–±—ã—Ç–∏—è"""
    return news_analyzer.get_upcoming_macro_events()


async def detect_manipulations() -> List[Dict]:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏"""
    return await news_analyzer.detect_manipulation_news()


# ==================== –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –° SMART ANALYZER ====================

async def enhance_setup_with_news(setup: Any, coin: str) -> Any:
    """
    –£–ª—É—á—à–∏—Ç—å —Ç–æ—Ä–≥–æ–≤—ã–π —Å–µ—Ç–∞–ø –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π
    
    Args:
        setup: TradeSetup –æ–±—ä–µ–∫—Ç –∏–∑ smart_analyzer
        coin: –°–∏–º–≤–æ–ª –º–æ–Ω–µ—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä 'BTC')
    
    Returns:
        –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π setup —Å —É—á—ë—Ç–æ–º –Ω–æ–≤–æ—Å—Ç–µ–π
    """
    if setup is None:
        return None
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –º–æ–Ω–µ—Ç—ã
        news_events = await get_news_for_coin(coin)
        
        if not news_events:
            return setup
        
        # –°—á–∏—Ç–∞–µ–º —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
        bullish_count = sum(1 for e in news_events[:5] if e.sentiment.value > 0)
        bearish_count = sum(1 for e in news_events[:5] if e.sentiment.value < 0)
        
        # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º confidence
        setup_direction = setup.direction.upper()
        
        if setup_direction == 'LONG' and bullish_count > bearish_count:
            # –ù–æ–≤–æ—Å—Ç–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç –ª–æ–Ω–≥
            boost = min(0.1, bullish_count * 0.02)
            setup.confidence = min(0.95, setup.confidence + boost)
            setup.reasoning.insert(0, f"üì∞ –ù–æ–≤–æ—Å—Ç–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç ({bullish_count} –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö)")
            logger.info(f"[NEWS] {coin}: News boost +{boost:.0%} for LONG")
            
        elif setup_direction == 'SHORT' and bearish_count > bullish_count:
            # –ù–æ–≤–æ—Å—Ç–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç —à–æ—Ä—Ç
            boost = min(0.1, bearish_count * 0.02)
            setup.confidence = min(0.95, setup.confidence + boost)
            setup.reasoning.insert(0, f"üì∞ –ù–æ–≤–æ—Å—Ç–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç ({bearish_count} –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö)")
            logger.info(f"[NEWS] {coin}: News boost +{boost:.0%} for SHORT")
            
        elif (setup_direction == 'LONG' and bearish_count > bullish_count + 2) or \
             (setup_direction == 'SHORT' and bullish_count > bearish_count + 2):
            # –ù–æ–≤–æ—Å—Ç–∏ –ü–†–û–¢–ò–í–û–†–ï–ß–ê–¢ —Å–µ—Ç–∞–ø—É
            penalty = 0.1
            setup.confidence = max(0.3, setup.confidence - penalty)
            setup.reasoning.insert(0, f"‚ö†Ô∏è –ù–æ–≤–æ—Å—Ç–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∞—Ç —Å–µ—Ç–∞–ø—É")
            logger.warning(f"[NEWS] {coin}: News penalty -{penalty:.0%}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞–∂–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –≤ reasoning
        critical_news = [e for e in news_events[:3] if e.impact.value >= NewsImpact.HIGH.value]
        for news in critical_news[:2]:
            setup.reasoning.append(f"üì∞ {news.title[:50]}...")
        
    except Exception as e:
        logger.warning(f"[NEWS] Error enhancing setup: {e}")
    
    return setup


async def get_news_trading_opportunities() -> List[Dict]:
    """
    –ü–æ–ª—É—á–∏—Ç—å —Ç–æ—Ä–≥–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤–æ—Å—Ç–µ–π
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–¥–µ–ª–æ–∫
    """
    signals = await get_news_signals()
    
    opportunities = []
    
    for signal in signals[:5]:  # –¢–æ–ø-5 —Å–∏–≥–Ω–∞–ª–æ–≤
        if signal.confidence >= 0.6:
            opportunities.append({
                'direction': signal.direction,
                'coins': signal.affected_coins,
                'confidence': signal.confidence,
                'reasoning': signal.reasoning,
                'source': signal.source,
                'time_sensitive': signal.time_sensitive,
                'expires_at': signal.expires_at.isoformat()
            })
    
    return opportunities
